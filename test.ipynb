{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to Data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data/cifar-100-python.tar.gz to Data/\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "filename = \"cifar-100-python.tar.gz\"\n",
    "tgz_md5 = \"eb9058c3a382ffc7106e4002c42a8d85\"\n",
    "datasetRoot = \"Data/\"\n",
    "\n",
    "torchvision.datasets.utils.download_and_extract_archive(url, datasetRoot, filename=filename, md5=tgz_md5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def load_external_image(target_dataset, class_type, original_label):\n",
    "    dict = unpickle(\"Data/cifar-100-python/train\")\n",
    "    labels = unpickle(\"Data/cifar-100-python/meta\")\n",
    "    # get the data of the first picture whose label is the same as the original label\n",
    "    images = []\n",
    "    if class_type == b\"fine_labels\":\n",
    "        target_label_index = labels[b'fine_label_names'].index(original_label)\n",
    "    else:\n",
    "        target_label_index = labels[b'coarse_label_names'].index(original_label)\n",
    "    \n",
    "    for i in range(len(dict[class_type])):\n",
    "        if dict[class_type][i] == target_label_index:\n",
    "            img_data = dict[b'data'][i]\n",
    "            img_data = img_data.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "            img = Image.fromarray(img_data)\n",
    "            images.append(img)\n",
    "    \n",
    "    img = Image.fromarray(img_data)\n",
    "\n",
    "    if target_dataset == \"cifar10\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "    transformed_images = [transform(img) for img in images]\n",
    "    return transformed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_external_image(\"cifar10\", b'fine_labels', b'shark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = load_external_image('Data/cifar-100-python/train', \"cifar100\", \"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'filenames'\n",
      "b'batch_label'\n",
      "b'fine_labels'\n",
      "b'coarse_labels'\n",
      "b'data'\n"
     ]
    }
   ],
   "source": [
    "for key in dict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = unpickle('Data/cifar-100-python/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'fine_label_names'\n",
      "b'coarse_label_names'\n"
     ]
    }
   ],
   "source": [
    "for key in label.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index of label shark\n",
    "label[b'fine_label_names'].index(b'shark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38, Test size: 10\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import PoisonDetector\n",
    "\n",
    "PoisonDetector.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/100, Loss: 1.585113525390625\n",
      "Epoch 2/100, Loss: 2.1318106651306152\n",
      "Epoch 3/100, Loss: 0.9572048187255859\n",
      "Epoch 4/100, Loss: 0.8779937624931335\n",
      "Epoch 5/100, Loss: 0.3746914863586426\n",
      "Epoch 6/100, Loss: 1.2835222482681274\n",
      "Epoch 7/100, Loss: 1.4428517818450928\n",
      "Epoch 8/100, Loss: 0.7479381561279297\n",
      "Epoch 9/100, Loss: 1.230881690979004\n",
      "Epoch 10/100, Loss: 1.233994722366333\n",
      "Epoch 11/100, Loss: 1.51222825050354\n",
      "Epoch 12/100, Loss: 1.1675598621368408\n",
      "Epoch 13/100, Loss: 0.6967612504959106\n",
      "Epoch 14/100, Loss: 1.6129182577133179\n",
      "Epoch 15/100, Loss: 1.3088788986206055\n",
      "Epoch 16/100, Loss: 0.8077686429023743\n",
      "Epoch 17/100, Loss: 0.7980876564979553\n",
      "Epoch 18/100, Loss: 1.0025535821914673\n",
      "Epoch 19/100, Loss: 0.8103345632553101\n",
      "Epoch 20/100, Loss: 1.5276771783828735\n",
      "Epoch 21/100, Loss: 1.4844427108764648\n",
      "Epoch 22/100, Loss: 1.0785460472106934\n",
      "Epoch 23/100, Loss: 1.4019566774368286\n",
      "Epoch 24/100, Loss: 0.42173972725868225\n",
      "Epoch 25/100, Loss: 1.079628825187683\n",
      "Epoch 26/100, Loss: 0.9991686940193176\n",
      "Epoch 27/100, Loss: 1.155907154083252\n",
      "Epoch 28/100, Loss: 0.9493645429611206\n",
      "Epoch 29/100, Loss: 1.0535647869110107\n",
      "Epoch 30/100, Loss: 1.659470558166504\n",
      "Epoch 31/100, Loss: 0.8472267389297485\n",
      "Epoch 32/100, Loss: 1.1029651165008545\n",
      "Epoch 33/100, Loss: 1.1107518672943115\n",
      "Epoch 34/100, Loss: 0.629034161567688\n",
      "Epoch 35/100, Loss: 1.6012217998504639\n",
      "Epoch 36/100, Loss: 0.7024217844009399\n",
      "Epoch 37/100, Loss: 1.2010807991027832\n",
      "Epoch 38/100, Loss: 1.4252070188522339\n",
      "Epoch 39/100, Loss: 1.3159034252166748\n",
      "Epoch 40/100, Loss: 0.994032084941864\n",
      "Epoch 41/100, Loss: 0.8864324688911438\n",
      "Epoch 42/100, Loss: 1.1441757678985596\n",
      "Epoch 43/100, Loss: 1.227900505065918\n",
      "Epoch 44/100, Loss: 1.475618600845337\n",
      "Epoch 45/100, Loss: 0.82848060131073\n",
      "Epoch 46/100, Loss: 1.2057558298110962\n",
      "Epoch 47/100, Loss: 0.9182537794113159\n",
      "Epoch 48/100, Loss: 1.4554444551467896\n",
      "Epoch 49/100, Loss: 1.1203817129135132\n",
      "Epoch 50/100, Loss: 0.4882794916629791\n",
      "Epoch 51/100, Loss: 1.293576955795288\n",
      "Epoch 52/100, Loss: 1.6017707586288452\n",
      "Epoch 53/100, Loss: 0.6749943494796753\n",
      "Epoch 54/100, Loss: 0.52352374792099\n",
      "Epoch 55/100, Loss: 0.9277030825614929\n",
      "Epoch 56/100, Loss: 0.965290904045105\n",
      "Epoch 57/100, Loss: 1.174745798110962\n",
      "Epoch 58/100, Loss: 0.9526033401489258\n",
      "Epoch 59/100, Loss: 1.1526187658309937\n",
      "Epoch 60/100, Loss: 1.6705372333526611\n",
      "Epoch 61/100, Loss: 1.0185606479644775\n",
      "Epoch 62/100, Loss: 1.557504653930664\n",
      "Epoch 63/100, Loss: 0.6688931584358215\n",
      "Epoch 64/100, Loss: 1.201409101486206\n",
      "Epoch 65/100, Loss: 1.2065744400024414\n",
      "Epoch 66/100, Loss: 1.8103948831558228\n",
      "Epoch 67/100, Loss: 1.0727524757385254\n",
      "Epoch 68/100, Loss: 1.123028039932251\n",
      "Epoch 69/100, Loss: 0.9810901880264282\n",
      "Epoch 70/100, Loss: 0.8767213821411133\n",
      "Epoch 71/100, Loss: 0.7134156227111816\n",
      "Epoch 72/100, Loss: 1.081815481185913\n",
      "Epoch 73/100, Loss: 0.8964222073554993\n",
      "Epoch 74/100, Loss: 0.5183001756668091\n",
      "Epoch 75/100, Loss: 1.07699716091156\n",
      "Epoch 76/100, Loss: 0.5763136148452759\n",
      "Epoch 77/100, Loss: 0.9261012077331543\n",
      "Epoch 78/100, Loss: 0.9243815541267395\n",
      "Epoch 79/100, Loss: 1.1983264684677124\n",
      "Epoch 80/100, Loss: 0.7190646529197693\n",
      "Epoch 81/100, Loss: 0.8131541013717651\n",
      "Epoch 82/100, Loss: 0.8664185404777527\n",
      "Epoch 83/100, Loss: 0.31302347779273987\n",
      "Epoch 84/100, Loss: 1.1116536855697632\n",
      "Epoch 85/100, Loss: 0.8066738843917847\n",
      "Epoch 86/100, Loss: 1.5445334911346436\n",
      "Epoch 87/100, Loss: 0.2202988862991333\n",
      "Epoch 88/100, Loss: 1.330730676651001\n",
      "Epoch 89/100, Loss: 0.8213561773300171\n",
      "Epoch 90/100, Loss: 0.8756927251815796\n",
      "Epoch 91/100, Loss: 0.6566619277000427\n",
      "Epoch 92/100, Loss: 0.7383955717086792\n",
      "Epoch 93/100, Loss: 0.7346954941749573\n",
      "Epoch 94/100, Loss: 0.8425434827804565\n",
      "Epoch 95/100, Loss: 0.547781765460968\n",
      "Epoch 96/100, Loss: 0.7296756505966187\n",
      "Epoch 97/100, Loss: 0.5876844525337219\n",
      "Epoch 98/100, Loss: 0.1272471398115158\n",
      "Epoch 99/100, Loss: 0.8647441864013672\n",
      "Epoch 100/100, Loss: 0.653328537940979\n",
      "Accuracy: 66.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "import PoisonDetector\n",
    "\n",
    "PoisonDetector.run(adv_root_dir='Sequences/adversarial', clean_root_dir='Sequences/clean', model_path='cons_non_binary_model.pth',is_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38, Test size: 10\n",
      "Accuracy: 18.75%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.test(model_path='cons_non_binary_model.pth', is_binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/100, Loss: 0.2751500606536865\n",
      "Epoch 2/100, Loss: 0.35544857382774353\n",
      "Epoch 3/100, Loss: 0.6137434244155884\n",
      "Epoch 4/100, Loss: 0.5715507864952087\n",
      "Epoch 5/100, Loss: 0.10921456664800644\n",
      "Epoch 6/100, Loss: 0.2351166009902954\n",
      "Epoch 7/100, Loss: 0.10090167820453644\n",
      "Epoch 8/100, Loss: 0.056595586240291595\n",
      "Epoch 9/100, Loss: 0.12079402059316635\n",
      "Epoch 10/100, Loss: 0.2735498249530792\n",
      "Epoch 11/100, Loss: 0.23675914108753204\n",
      "Epoch 12/100, Loss: 0.1816578060388565\n",
      "Epoch 13/100, Loss: 0.15992823243141174\n",
      "Epoch 14/100, Loss: 0.20547203719615936\n",
      "Epoch 15/100, Loss: 0.3125832676887512\n",
      "Epoch 16/100, Loss: 0.27640020847320557\n",
      "Epoch 17/100, Loss: 0.12006881088018417\n",
      "Epoch 18/100, Loss: 0.11419693380594254\n",
      "Epoch 19/100, Loss: 0.4505597651004791\n",
      "Epoch 20/100, Loss: 0.0980360209941864\n",
      "Epoch 21/100, Loss: 0.06815215200185776\n",
      "Epoch 22/100, Loss: 0.4816989302635193\n",
      "Epoch 23/100, Loss: 0.0192424189299345\n",
      "Epoch 24/100, Loss: 0.10339409112930298\n",
      "Epoch 25/100, Loss: 0.08595714718103409\n",
      "Epoch 26/100, Loss: 0.06147225946187973\n",
      "Epoch 27/100, Loss: 0.1168987974524498\n",
      "Epoch 28/100, Loss: 0.06276549398899078\n",
      "Epoch 29/100, Loss: 0.3049216866493225\n",
      "Epoch 30/100, Loss: 0.1671154797077179\n",
      "Epoch 31/100, Loss: 0.0267513245344162\n",
      "Epoch 32/100, Loss: 0.3618379831314087\n",
      "Epoch 33/100, Loss: 0.2722632884979248\n",
      "Epoch 34/100, Loss: 0.05318071320652962\n",
      "Epoch 35/100, Loss: 0.09481097757816315\n",
      "Epoch 36/100, Loss: 0.13943734765052795\n",
      "Epoch 37/100, Loss: 0.04786147549748421\n",
      "Epoch 38/100, Loss: 0.020613495260477066\n",
      "Epoch 39/100, Loss: 0.07251519709825516\n",
      "Epoch 40/100, Loss: 0.042205650359392166\n",
      "Epoch 41/100, Loss: 0.38576075434684753\n",
      "Epoch 42/100, Loss: 0.2733280062675476\n",
      "Epoch 43/100, Loss: 0.20627860724925995\n",
      "Epoch 44/100, Loss: 0.26085013151168823\n",
      "Epoch 45/100, Loss: 0.24604880809783936\n",
      "Epoch 46/100, Loss: 0.14849649369716644\n",
      "Epoch 47/100, Loss: 0.3680638372898102\n",
      "Epoch 48/100, Loss: 0.5400698781013489\n",
      "Epoch 49/100, Loss: 0.4500846862792969\n",
      "Epoch 50/100, Loss: 0.14255329966545105\n",
      "Epoch 51/100, Loss: 0.13038204610347748\n",
      "Epoch 52/100, Loss: 0.2741026282310486\n",
      "Epoch 53/100, Loss: 0.17552904784679413\n",
      "Epoch 54/100, Loss: 0.3747098743915558\n",
      "Epoch 55/100, Loss: 0.033199287950992584\n",
      "Epoch 56/100, Loss: 0.1495549976825714\n",
      "Epoch 57/100, Loss: 0.18656155467033386\n",
      "Epoch 58/100, Loss: 0.13678419589996338\n",
      "Epoch 59/100, Loss: 0.062263138592243195\n",
      "Epoch 60/100, Loss: 0.03782176971435547\n",
      "Epoch 61/100, Loss: 0.2374485731124878\n",
      "Epoch 62/100, Loss: 0.4122535288333893\n",
      "Epoch 63/100, Loss: 0.07549090683460236\n",
      "Epoch 64/100, Loss: 0.38733258843421936\n",
      "Epoch 65/100, Loss: 0.11467919498682022\n",
      "Epoch 66/100, Loss: 0.14990726113319397\n",
      "Epoch 67/100, Loss: 0.3720303773880005\n",
      "Epoch 68/100, Loss: 0.14234203100204468\n",
      "Epoch 69/100, Loss: 0.09831978380680084\n",
      "Epoch 70/100, Loss: 0.19551125168800354\n",
      "Epoch 71/100, Loss: 0.07940837740898132\n",
      "Epoch 72/100, Loss: 0.04245121031999588\n",
      "Epoch 73/100, Loss: 0.15892662107944489\n",
      "Epoch 74/100, Loss: 0.38209158182144165\n",
      "Epoch 75/100, Loss: 0.35682421922683716\n",
      "Epoch 76/100, Loss: 0.22988800704479218\n",
      "Epoch 77/100, Loss: 0.3509681522846222\n",
      "Epoch 78/100, Loss: 0.35880452394485474\n",
      "Epoch 79/100, Loss: 0.08767883479595184\n",
      "Epoch 80/100, Loss: 0.022001978009939194\n",
      "Epoch 81/100, Loss: 0.2305106818675995\n",
      "Epoch 82/100, Loss: 0.11444602161645889\n",
      "Epoch 83/100, Loss: 0.05654815584421158\n",
      "Epoch 84/100, Loss: 0.04191374033689499\n",
      "Epoch 85/100, Loss: 0.015447978861629963\n",
      "Epoch 86/100, Loss: 0.1418282687664032\n",
      "Epoch 87/100, Loss: 0.4114609658718109\n",
      "Epoch 88/100, Loss: 0.3815281093120575\n",
      "Epoch 89/100, Loss: 0.027617597952485085\n",
      "Epoch 90/100, Loss: 0.07275646179914474\n",
      "Epoch 91/100, Loss: 0.00531418900936842\n",
      "Epoch 92/100, Loss: 0.04298614710569382\n",
      "Epoch 93/100, Loss: 0.010677940212190151\n",
      "Epoch 94/100, Loss: 0.07219405472278595\n",
      "Epoch 95/100, Loss: 0.0031146793626248837\n",
      "Epoch 96/100, Loss: 0.02129378542304039\n",
      "Epoch 97/100, Loss: 0.004218270070850849\n",
      "Epoch 98/100, Loss: 0.023075854405760765\n",
      "Epoch 99/100, Loss: 0.0006298787193372846\n",
      "Epoch 100/100, Loss: 0.00738013768568635\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/adversarial', clean_root_dir='Sequences/clean', model_path='cons_binary_model.pth',is_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38, Test size: 10\n",
      "Train size: 38, Test size: 10\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.test(model_path='cons_binary_model.pth', is_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attack_interval = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 1.2924387454986572\n",
      "Epoch 2/200, Loss: 1.4635095596313477\n",
      "Epoch 3/200, Loss: 1.5442631244659424\n",
      "Epoch 4/200, Loss: 1.4801257848739624\n",
      "Epoch 5/200, Loss: 1.086327314376831\n",
      "Epoch 6/200, Loss: 1.1011134386062622\n",
      "Epoch 7/200, Loss: 1.163374662399292\n",
      "Epoch 8/200, Loss: 1.4352134466171265\n",
      "Epoch 9/200, Loss: 1.4576610326766968\n",
      "Epoch 10/200, Loss: 1.8815319538116455\n",
      "Epoch 11/200, Loss: 1.098044514656067\n",
      "Epoch 12/200, Loss: 1.4982740879058838\n",
      "Epoch 13/200, Loss: 1.2346012592315674\n",
      "Epoch 14/200, Loss: 1.1715948581695557\n",
      "Epoch 15/200, Loss: 1.295647382736206\n",
      "Epoch 16/200, Loss: 1.1935713291168213\n",
      "Epoch 17/200, Loss: 1.3816616535186768\n",
      "Epoch 18/200, Loss: 1.2016959190368652\n",
      "Epoch 19/200, Loss: 1.6812444925308228\n",
      "Epoch 20/200, Loss: 1.8744754791259766\n",
      "Epoch 21/200, Loss: 1.7177454233169556\n",
      "Epoch 22/200, Loss: 0.7670254707336426\n",
      "Epoch 23/200, Loss: 1.557218313217163\n",
      "Epoch 24/200, Loss: 1.1622488498687744\n",
      "Epoch 25/200, Loss: 1.0739871263504028\n",
      "Epoch 26/200, Loss: 1.1791212558746338\n",
      "Epoch 27/200, Loss: 1.0140923261642456\n",
      "Epoch 28/200, Loss: 0.5707324147224426\n",
      "Epoch 29/200, Loss: 1.325336217880249\n",
      "Epoch 30/200, Loss: 1.3865275382995605\n",
      "Epoch 31/200, Loss: 1.4848248958587646\n",
      "Epoch 32/200, Loss: 1.0060328245162964\n",
      "Epoch 33/200, Loss: 0.589404284954071\n",
      "Epoch 34/200, Loss: 0.911988377571106\n",
      "Epoch 35/200, Loss: 1.3346384763717651\n",
      "Epoch 36/200, Loss: 0.907784104347229\n",
      "Epoch 37/200, Loss: 0.6891599893569946\n",
      "Epoch 38/200, Loss: 1.061152458190918\n",
      "Epoch 39/200, Loss: 0.5397077798843384\n",
      "Epoch 40/200, Loss: 1.0841474533081055\n",
      "Epoch 41/200, Loss: 1.9154962301254272\n",
      "Epoch 42/200, Loss: 0.8743136525154114\n",
      "Epoch 43/200, Loss: 0.6250913739204407\n",
      "Epoch 44/200, Loss: 0.49016445875167847\n",
      "Epoch 45/200, Loss: 1.2917698621749878\n",
      "Epoch 46/200, Loss: 1.102884292602539\n",
      "Epoch 47/200, Loss: 0.7255604267120361\n",
      "Epoch 48/200, Loss: 0.583559513092041\n",
      "Epoch 49/200, Loss: 0.8747988939285278\n",
      "Epoch 50/200, Loss: 0.9165488481521606\n",
      "Epoch 51/200, Loss: 0.8834068179130554\n",
      "Epoch 52/200, Loss: 0.48779597878456116\n",
      "Epoch 53/200, Loss: 0.7741721272468567\n",
      "Epoch 54/200, Loss: 0.6409328579902649\n",
      "Epoch 55/200, Loss: 0.7928078770637512\n",
      "Epoch 56/200, Loss: 0.8835604786872864\n",
      "Epoch 57/200, Loss: 0.6139692664146423\n",
      "Epoch 58/200, Loss: 1.0024802684783936\n",
      "Epoch 59/200, Loss: 0.6455696821212769\n",
      "Epoch 60/200, Loss: 0.8084913492202759\n",
      "Epoch 61/200, Loss: 0.9486163258552551\n",
      "Epoch 62/200, Loss: 0.5275393724441528\n",
      "Epoch 63/200, Loss: 0.756731390953064\n",
      "Epoch 64/200, Loss: 0.5749295949935913\n",
      "Epoch 65/200, Loss: 0.7570479512214661\n",
      "Epoch 66/200, Loss: 1.1489875316619873\n",
      "Epoch 67/200, Loss: 0.6849104166030884\n",
      "Epoch 68/200, Loss: 1.6210033893585205\n",
      "Epoch 69/200, Loss: 0.6219383478164673\n",
      "Epoch 70/200, Loss: 1.2417795658111572\n",
      "Epoch 71/200, Loss: 0.7862380743026733\n",
      "Epoch 72/200, Loss: 0.7724287509918213\n",
      "Epoch 73/200, Loss: 0.8058689832687378\n",
      "Epoch 74/200, Loss: 0.9743096232414246\n",
      "Epoch 75/200, Loss: 0.4838378429412842\n",
      "Epoch 76/200, Loss: 0.8521075248718262\n",
      "Epoch 77/200, Loss: 1.468204379081726\n",
      "Epoch 78/200, Loss: 0.6197991371154785\n",
      "Epoch 79/200, Loss: 0.6366903781890869\n",
      "Epoch 80/200, Loss: 0.6292233467102051\n",
      "Epoch 81/200, Loss: 0.9490916132926941\n",
      "Epoch 82/200, Loss: 0.7241920828819275\n",
      "Epoch 83/200, Loss: 0.7444932460784912\n",
      "Epoch 84/200, Loss: 0.8450385928153992\n",
      "Epoch 85/200, Loss: 0.8044989705085754\n",
      "Epoch 86/200, Loss: 0.7779335975646973\n",
      "Epoch 87/200, Loss: 0.8738982081413269\n",
      "Epoch 88/200, Loss: 0.6719604134559631\n",
      "Epoch 89/200, Loss: 0.3345491588115692\n",
      "Epoch 90/200, Loss: 0.9258254766464233\n",
      "Epoch 91/200, Loss: 0.5985562801361084\n",
      "Epoch 92/200, Loss: 0.402620792388916\n",
      "Epoch 93/200, Loss: 0.38616156578063965\n",
      "Epoch 94/200, Loss: 0.9958648681640625\n",
      "Epoch 95/200, Loss: 1.3260104656219482\n",
      "Epoch 96/200, Loss: 0.8348596692085266\n",
      "Epoch 97/200, Loss: 0.3470360040664673\n",
      "Epoch 98/200, Loss: 0.7436542510986328\n",
      "Epoch 99/200, Loss: 0.37955302000045776\n",
      "Epoch 100/200, Loss: 0.6323443055152893\n",
      "Epoch 101/200, Loss: 0.39618852734565735\n",
      "Epoch 102/200, Loss: 0.7552523016929626\n",
      "Epoch 103/200, Loss: 0.2936221659183502\n",
      "Epoch 104/200, Loss: 0.500952959060669\n",
      "Epoch 105/200, Loss: 0.48785120248794556\n",
      "Epoch 106/200, Loss: 0.7486129403114319\n",
      "Epoch 107/200, Loss: 1.0705907344818115\n",
      "Epoch 108/200, Loss: 0.6101006865501404\n",
      "Epoch 109/200, Loss: 0.6761757731437683\n",
      "Epoch 110/200, Loss: 0.686699628829956\n",
      "Epoch 111/200, Loss: 0.23042377829551697\n",
      "Epoch 112/200, Loss: 0.2191198617219925\n",
      "Epoch 113/200, Loss: 0.6044798493385315\n",
      "Epoch 114/200, Loss: 0.8029586672782898\n",
      "Epoch 115/200, Loss: 0.7997755408287048\n",
      "Epoch 116/200, Loss: 1.0373494625091553\n",
      "Epoch 117/200, Loss: 0.4454655051231384\n",
      "Epoch 118/200, Loss: 0.33917632699012756\n",
      "Epoch 119/200, Loss: 0.7289236783981323\n",
      "Epoch 120/200, Loss: 0.5892861485481262\n",
      "Epoch 121/200, Loss: 0.3649493455886841\n",
      "Epoch 122/200, Loss: 0.48987942934036255\n",
      "Epoch 123/200, Loss: 0.3900715708732605\n",
      "Epoch 124/200, Loss: 0.39781612157821655\n",
      "Epoch 125/200, Loss: 0.4527064263820648\n",
      "Epoch 126/200, Loss: 0.7493467926979065\n",
      "Epoch 127/200, Loss: 0.6275411248207092\n",
      "Epoch 128/200, Loss: 0.6326984167098999\n",
      "Epoch 129/200, Loss: 0.38324040174484253\n",
      "Epoch 130/200, Loss: 0.24933871626853943\n",
      "Epoch 131/200, Loss: 0.4227842688560486\n",
      "Epoch 132/200, Loss: 0.3035436272621155\n",
      "Epoch 133/200, Loss: 0.3732783794403076\n",
      "Epoch 134/200, Loss: 1.0504034757614136\n",
      "Epoch 135/200, Loss: 1.4654862880706787\n",
      "Epoch 136/200, Loss: 0.6057458519935608\n",
      "Epoch 137/200, Loss: 0.5720881223678589\n",
      "Epoch 138/200, Loss: 0.7444504499435425\n",
      "Epoch 139/200, Loss: 0.6811257004737854\n",
      "Epoch 140/200, Loss: 0.4681297838687897\n",
      "Epoch 141/200, Loss: 0.7837415337562561\n",
      "Epoch 142/200, Loss: 0.5823625922203064\n",
      "Epoch 143/200, Loss: 1.074994444847107\n",
      "Epoch 144/200, Loss: 0.7584814429283142\n",
      "Epoch 145/200, Loss: 0.39763835072517395\n",
      "Epoch 146/200, Loss: 0.7028979063034058\n",
      "Epoch 147/200, Loss: 0.8225420117378235\n",
      "Epoch 148/200, Loss: 0.5069092512130737\n",
      "Epoch 149/200, Loss: 0.6673243641853333\n",
      "Epoch 150/200, Loss: 0.34577614068984985\n",
      "Epoch 151/200, Loss: 1.204714059829712\n",
      "Epoch 152/200, Loss: 0.7593141794204712\n",
      "Epoch 153/200, Loss: 0.5522068738937378\n",
      "Epoch 154/200, Loss: 0.4422820210456848\n",
      "Epoch 155/200, Loss: 0.6873137354850769\n",
      "Epoch 156/200, Loss: 0.9596307873725891\n",
      "Epoch 157/200, Loss: 0.9280480146408081\n",
      "Epoch 158/200, Loss: 0.3906492590904236\n",
      "Epoch 159/200, Loss: 0.15627369284629822\n",
      "Epoch 160/200, Loss: 0.6964813470840454\n",
      "Epoch 161/200, Loss: 0.6490857601165771\n",
      "Epoch 162/200, Loss: 0.24642840027809143\n",
      "Epoch 163/200, Loss: 0.9023134112358093\n",
      "Epoch 164/200, Loss: 0.42103084921836853\n",
      "Epoch 165/200, Loss: 0.7041810154914856\n",
      "Epoch 166/200, Loss: 0.3683892786502838\n",
      "Epoch 167/200, Loss: 0.33778420090675354\n",
      "Epoch 168/200, Loss: 0.3554016947746277\n",
      "Epoch 169/200, Loss: 0.6566317677497864\n",
      "Epoch 170/200, Loss: 0.7531810402870178\n",
      "Epoch 171/200, Loss: 0.6938234567642212\n",
      "Epoch 172/200, Loss: 0.4661989212036133\n",
      "Epoch 173/200, Loss: 0.44259485602378845\n",
      "Epoch 174/200, Loss: 0.5669607520103455\n",
      "Epoch 175/200, Loss: 0.3669142425060272\n",
      "Epoch 176/200, Loss: 0.4969143867492676\n",
      "Epoch 177/200, Loss: 0.221788689494133\n",
      "Epoch 178/200, Loss: 0.43024349212646484\n",
      "Epoch 179/200, Loss: 0.2360849380493164\n",
      "Epoch 180/200, Loss: 0.35732555389404297\n",
      "Epoch 181/200, Loss: 0.6036202907562256\n",
      "Epoch 182/200, Loss: 0.487417072057724\n",
      "Epoch 183/200, Loss: 0.3048054873943329\n",
      "Epoch 184/200, Loss: 0.4992856979370117\n",
      "Epoch 185/200, Loss: 0.26215672492980957\n",
      "Epoch 186/200, Loss: 0.35617008805274963\n",
      "Epoch 187/200, Loss: 0.3852277398109436\n",
      "Epoch 188/200, Loss: 0.5998247265815735\n",
      "Epoch 189/200, Loss: 0.669106662273407\n",
      "Epoch 190/200, Loss: 0.26135995984077454\n",
      "Epoch 191/200, Loss: 0.4149371087551117\n",
      "Epoch 192/200, Loss: 2.172757863998413\n",
      "Epoch 193/200, Loss: 1.224961280822754\n",
      "Epoch 194/200, Loss: 0.9898150563240051\n",
      "Epoch 195/200, Loss: 0.42221933603286743\n",
      "Epoch 196/200, Loss: 1.1909255981445312\n",
      "Epoch 197/200, Loss: 0.765458881855011\n",
      "Epoch 198/200, Loss: 0.6107374429702759\n",
      "Epoch 199/200, Loss: 0.9713271856307983\n",
      "Epoch 200/200, Loss: 0.7420865297317505\n",
      "Accuracy: 55.55555555555556%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-2', clean_root_dir='Sequences/clean', model_path='alter2_non_binary_model.pth',is_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 1.7707483768463135\n",
      "Epoch 2/200, Loss: 1.0887377262115479\n",
      "Epoch 3/200, Loss: 0.9057003855705261\n",
      "Epoch 4/200, Loss: 1.136815071105957\n",
      "Epoch 5/200, Loss: 1.53787362575531\n",
      "Epoch 6/200, Loss: 1.3536672592163086\n",
      "Epoch 7/200, Loss: 1.450284719467163\n",
      "Epoch 8/200, Loss: 1.0285495519638062\n",
      "Epoch 9/200, Loss: 1.2550621032714844\n",
      "Epoch 10/200, Loss: 1.3014342784881592\n",
      "Epoch 11/200, Loss: 1.19786536693573\n",
      "Epoch 12/200, Loss: 1.5115633010864258\n",
      "Epoch 13/200, Loss: 1.558163046836853\n",
      "Epoch 14/200, Loss: 1.3241811990737915\n",
      "Epoch 15/200, Loss: 1.1426805257797241\n",
      "Epoch 16/200, Loss: 1.791878342628479\n",
      "Epoch 17/200, Loss: 1.1195329427719116\n",
      "Epoch 18/200, Loss: 0.9860925674438477\n",
      "Epoch 19/200, Loss: 1.0599550008773804\n",
      "Epoch 20/200, Loss: 0.8817462921142578\n",
      "Epoch 21/200, Loss: 1.7856171131134033\n",
      "Epoch 22/200, Loss: 1.0043776035308838\n",
      "Epoch 23/200, Loss: 1.510406732559204\n",
      "Epoch 24/200, Loss: 1.7878713607788086\n",
      "Epoch 25/200, Loss: 1.6910350322723389\n",
      "Epoch 26/200, Loss: 1.6368286609649658\n",
      "Epoch 27/200, Loss: 1.057248830795288\n",
      "Epoch 28/200, Loss: 0.6916593313217163\n",
      "Epoch 29/200, Loss: 1.0625426769256592\n",
      "Epoch 30/200, Loss: 0.7318455576896667\n",
      "Epoch 31/200, Loss: 1.281785249710083\n",
      "Epoch 32/200, Loss: 1.0891116857528687\n",
      "Epoch 33/200, Loss: 1.080078125\n",
      "Epoch 34/200, Loss: 1.337789535522461\n",
      "Epoch 35/200, Loss: 0.7078183889389038\n",
      "Epoch 36/200, Loss: 0.7091817259788513\n",
      "Epoch 37/200, Loss: 0.7290595769882202\n",
      "Epoch 38/200, Loss: 1.181061029434204\n",
      "Epoch 39/200, Loss: 1.4825029373168945\n",
      "Epoch 40/200, Loss: 0.79499351978302\n",
      "Epoch 41/200, Loss: 1.5098388195037842\n",
      "Epoch 42/200, Loss: 1.3618768453598022\n",
      "Epoch 43/200, Loss: 0.9189187288284302\n",
      "Epoch 44/200, Loss: 1.267195463180542\n",
      "Epoch 45/200, Loss: 0.7276530265808105\n",
      "Epoch 46/200, Loss: 1.0101090669631958\n",
      "Epoch 47/200, Loss: 1.0267679691314697\n",
      "Epoch 48/200, Loss: 0.9802775382995605\n",
      "Epoch 49/200, Loss: 0.6286935806274414\n",
      "Epoch 50/200, Loss: 1.6385433673858643\n",
      "Epoch 51/200, Loss: 0.9904300570487976\n",
      "Epoch 52/200, Loss: 1.68804931640625\n",
      "Epoch 53/200, Loss: 0.8248809576034546\n",
      "Epoch 54/200, Loss: 1.2798571586608887\n",
      "Epoch 55/200, Loss: 1.1001417636871338\n",
      "Epoch 56/200, Loss: 0.7090885639190674\n",
      "Epoch 57/200, Loss: 1.0458991527557373\n",
      "Epoch 58/200, Loss: 0.9862510561943054\n",
      "Epoch 59/200, Loss: 0.6539162397384644\n",
      "Epoch 60/200, Loss: 1.033651351928711\n",
      "Epoch 61/200, Loss: 1.069388747215271\n",
      "Epoch 62/200, Loss: 1.0356109142303467\n",
      "Epoch 63/200, Loss: 1.043103575706482\n",
      "Epoch 64/200, Loss: 0.33989405632019043\n",
      "Epoch 65/200, Loss: 0.8955646753311157\n",
      "Epoch 66/200, Loss: 0.680975079536438\n",
      "Epoch 67/200, Loss: 1.0509941577911377\n",
      "Epoch 68/200, Loss: 1.0733656883239746\n",
      "Epoch 69/200, Loss: 1.376933217048645\n",
      "Epoch 70/200, Loss: 0.6457741260528564\n",
      "Epoch 71/200, Loss: 1.015766978263855\n",
      "Epoch 72/200, Loss: 0.5980216860771179\n",
      "Epoch 73/200, Loss: 1.4807037115097046\n",
      "Epoch 74/200, Loss: 0.6038047671318054\n",
      "Epoch 75/200, Loss: 1.0789018869400024\n",
      "Epoch 76/200, Loss: 0.6673306226730347\n",
      "Epoch 77/200, Loss: 1.334029197692871\n",
      "Epoch 78/200, Loss: 0.39640694856643677\n",
      "Epoch 79/200, Loss: 0.5189768075942993\n",
      "Epoch 80/200, Loss: 1.0106523036956787\n",
      "Epoch 81/200, Loss: 0.8500581979751587\n",
      "Epoch 82/200, Loss: 0.2536773085594177\n",
      "Epoch 83/200, Loss: 0.631611704826355\n",
      "Epoch 84/200, Loss: 0.773943305015564\n",
      "Epoch 85/200, Loss: 0.5995005369186401\n",
      "Epoch 86/200, Loss: 1.0011913776397705\n",
      "Epoch 87/200, Loss: 1.3534643650054932\n",
      "Epoch 88/200, Loss: 0.7010841965675354\n",
      "Epoch 89/200, Loss: 0.8475836515426636\n",
      "Epoch 90/200, Loss: 1.0916554927825928\n",
      "Epoch 91/200, Loss: 0.7540028095245361\n",
      "Epoch 92/200, Loss: 0.6393482089042664\n",
      "Epoch 93/200, Loss: 0.7834225296974182\n",
      "Epoch 94/200, Loss: 0.5925352573394775\n",
      "Epoch 95/200, Loss: 0.2734997272491455\n",
      "Epoch 96/200, Loss: 0.4016387462615967\n",
      "Epoch 97/200, Loss: 0.42983999848365784\n",
      "Epoch 98/200, Loss: 0.8971022367477417\n",
      "Epoch 99/200, Loss: 0.8217690587043762\n",
      "Epoch 100/200, Loss: 0.4589383602142334\n",
      "Epoch 101/200, Loss: 0.5399506092071533\n",
      "Epoch 102/200, Loss: 0.5670430064201355\n",
      "Epoch 103/200, Loss: 0.6126774549484253\n",
      "Epoch 104/200, Loss: 0.2694271206855774\n",
      "Epoch 105/200, Loss: 1.043509602546692\n",
      "Epoch 106/200, Loss: 0.38373059034347534\n",
      "Epoch 107/200, Loss: 0.4901805818080902\n",
      "Epoch 108/200, Loss: 3.685098648071289\n",
      "Epoch 109/200, Loss: 1.9703069925308228\n",
      "Epoch 110/200, Loss: 1.4634443521499634\n",
      "Epoch 111/200, Loss: 1.1821093559265137\n",
      "Epoch 112/200, Loss: 1.2027603387832642\n",
      "Epoch 113/200, Loss: 1.4223225116729736\n",
      "Epoch 114/200, Loss: 0.962367832660675\n",
      "Epoch 115/200, Loss: 1.3329652547836304\n",
      "Epoch 116/200, Loss: 0.6074026226997375\n",
      "Epoch 117/200, Loss: 0.6690361499786377\n",
      "Epoch 118/200, Loss: 0.846298098564148\n",
      "Epoch 119/200, Loss: 0.5266209840774536\n",
      "Epoch 120/200, Loss: 0.835788905620575\n",
      "Epoch 121/200, Loss: 0.6658782958984375\n",
      "Epoch 122/200, Loss: 0.51601642370224\n",
      "Epoch 123/200, Loss: 0.7339915037155151\n",
      "Epoch 124/200, Loss: 1.1015965938568115\n",
      "Epoch 125/200, Loss: 0.9779758453369141\n",
      "Epoch 126/200, Loss: 0.7917495965957642\n",
      "Epoch 127/200, Loss: 1.0828725099563599\n",
      "Epoch 128/200, Loss: 0.9964712858200073\n",
      "Epoch 129/200, Loss: 0.6874300837516785\n",
      "Epoch 130/200, Loss: 0.6300885677337646\n",
      "Epoch 131/200, Loss: 0.47037839889526367\n",
      "Epoch 132/200, Loss: 0.535492479801178\n",
      "Epoch 133/200, Loss: 1.339224100112915\n",
      "Epoch 134/200, Loss: 0.6788902878761292\n",
      "Epoch 135/200, Loss: 0.9789870381355286\n",
      "Epoch 136/200, Loss: 0.4912649691104889\n",
      "Epoch 137/200, Loss: 0.41349363327026367\n",
      "Epoch 138/200, Loss: 0.8875502347946167\n",
      "Epoch 139/200, Loss: 0.2301003485918045\n",
      "Epoch 140/200, Loss: 0.7519715428352356\n",
      "Epoch 141/200, Loss: 0.713413655757904\n",
      "Epoch 142/200, Loss: 0.9790666699409485\n",
      "Epoch 143/200, Loss: 0.5664305686950684\n",
      "Epoch 144/200, Loss: 0.40309447050094604\n",
      "Epoch 145/200, Loss: 0.5652401447296143\n",
      "Epoch 146/200, Loss: 0.5651007890701294\n",
      "Epoch 147/200, Loss: 0.5939173698425293\n",
      "Epoch 148/200, Loss: 0.9551045298576355\n",
      "Epoch 149/200, Loss: 0.8327232599258423\n",
      "Epoch 150/200, Loss: 0.43859386444091797\n",
      "Epoch 151/200, Loss: 0.27820631861686707\n",
      "Epoch 152/200, Loss: 0.7934072017669678\n",
      "Epoch 153/200, Loss: 0.4346834719181061\n",
      "Epoch 154/200, Loss: 0.5002727508544922\n",
      "Epoch 155/200, Loss: 0.5916379690170288\n",
      "Epoch 156/200, Loss: 0.47866255044937134\n",
      "Epoch 157/200, Loss: 0.5392113924026489\n",
      "Epoch 158/200, Loss: 0.15435977280139923\n",
      "Epoch 159/200, Loss: 0.7276493310928345\n",
      "Epoch 160/200, Loss: 0.2201496809720993\n",
      "Epoch 161/200, Loss: 0.30132558941841125\n",
      "Epoch 162/200, Loss: 0.4318893551826477\n",
      "Epoch 163/200, Loss: 0.23674997687339783\n",
      "Epoch 164/200, Loss: 0.7653284668922424\n",
      "Epoch 165/200, Loss: 0.46745944023132324\n",
      "Epoch 166/200, Loss: 0.3568558394908905\n",
      "Epoch 167/200, Loss: 0.34720686078071594\n",
      "Epoch 168/200, Loss: 0.17707449197769165\n",
      "Epoch 169/200, Loss: 0.7905399799346924\n",
      "Epoch 170/200, Loss: 0.33615416288375854\n",
      "Epoch 171/200, Loss: 0.5204437375068665\n",
      "Epoch 172/200, Loss: 0.3941669464111328\n",
      "Epoch 173/200, Loss: 0.8631075024604797\n",
      "Epoch 174/200, Loss: 0.7005721926689148\n",
      "Epoch 175/200, Loss: 0.3043930232524872\n",
      "Epoch 176/200, Loss: 0.45232367515563965\n",
      "Epoch 177/200, Loss: 0.42377743124961853\n",
      "Epoch 178/200, Loss: 0.47303542494773865\n",
      "Epoch 179/200, Loss: 0.540665328502655\n",
      "Epoch 180/200, Loss: 0.28414884209632874\n",
      "Epoch 181/200, Loss: 0.6226262450218201\n",
      "Epoch 182/200, Loss: 0.28090113401412964\n",
      "Epoch 183/200, Loss: 0.06202295422554016\n",
      "Epoch 184/200, Loss: 0.17888575792312622\n",
      "Epoch 185/200, Loss: 0.6905679106712341\n",
      "Epoch 186/200, Loss: 0.938681423664093\n",
      "Epoch 187/200, Loss: 0.5702090859413147\n",
      "Epoch 188/200, Loss: 0.3541618287563324\n",
      "Epoch 189/200, Loss: 0.6746169924736023\n",
      "Epoch 190/200, Loss: 0.21314497292041779\n",
      "Epoch 191/200, Loss: 0.29150599241256714\n",
      "Epoch 192/200, Loss: 0.3620480000972748\n",
      "Epoch 193/200, Loss: 0.2794540822505951\n",
      "Epoch 194/200, Loss: 1.7261810302734375\n",
      "Epoch 195/200, Loss: 0.4956286549568176\n",
      "Epoch 196/200, Loss: 0.800505518913269\n",
      "Epoch 197/200, Loss: 1.0188868045806885\n",
      "Epoch 198/200, Loss: 0.5575013160705566\n",
      "Epoch 199/200, Loss: 0.4280884265899658\n",
      "Epoch 200/200, Loss: 1.07761549949646\n",
      "Accuracy: 58.333333333333336%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-3', clean_root_dir='Sequences/clean', model_path='alter3_non_binary_model.pth',is_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 1.7048927545547485\n",
      "Epoch 2/200, Loss: 1.6862123012542725\n",
      "Epoch 3/200, Loss: 0.7309714555740356\n",
      "Epoch 4/200, Loss: 1.9683490991592407\n",
      "Epoch 5/200, Loss: 1.7956600189208984\n",
      "Epoch 6/200, Loss: 0.741583526134491\n",
      "Epoch 7/200, Loss: 1.5586912631988525\n",
      "Epoch 8/200, Loss: 1.143585205078125\n",
      "Epoch 9/200, Loss: 1.2929906845092773\n",
      "Epoch 10/200, Loss: 1.667568564414978\n",
      "Epoch 11/200, Loss: 1.802260398864746\n",
      "Epoch 12/200, Loss: 0.8670908212661743\n",
      "Epoch 13/200, Loss: 1.8076608180999756\n",
      "Epoch 14/200, Loss: 1.273607611656189\n",
      "Epoch 15/200, Loss: 0.8369057774543762\n",
      "Epoch 16/200, Loss: 1.4729517698287964\n",
      "Epoch 17/200, Loss: 0.9092680215835571\n",
      "Epoch 18/200, Loss: 1.329638123512268\n",
      "Epoch 19/200, Loss: 1.5683635473251343\n",
      "Epoch 20/200, Loss: 2.0894999504089355\n",
      "Epoch 21/200, Loss: 1.4983298778533936\n",
      "Epoch 22/200, Loss: 1.9356616735458374\n",
      "Epoch 23/200, Loss: 1.9347730875015259\n",
      "Epoch 24/200, Loss: 1.3204174041748047\n",
      "Epoch 25/200, Loss: 0.627292275428772\n",
      "Epoch 26/200, Loss: 1.3915860652923584\n",
      "Epoch 27/200, Loss: 1.1481181383132935\n",
      "Epoch 28/200, Loss: 1.6363637447357178\n",
      "Epoch 29/200, Loss: 2.1545557975769043\n",
      "Epoch 30/200, Loss: 2.700759172439575\n",
      "Epoch 31/200, Loss: 1.6800792217254639\n",
      "Epoch 32/200, Loss: 1.2755800485610962\n",
      "Epoch 33/200, Loss: 1.679727554321289\n",
      "Epoch 34/200, Loss: 1.0165717601776123\n",
      "Epoch 35/200, Loss: 0.9609454274177551\n",
      "Epoch 36/200, Loss: 0.9555113911628723\n",
      "Epoch 37/200, Loss: 1.349661946296692\n",
      "Epoch 38/200, Loss: 1.3243147134780884\n",
      "Epoch 39/200, Loss: 0.9598355293273926\n",
      "Epoch 40/200, Loss: 0.9516285061836243\n",
      "Epoch 41/200, Loss: 0.9927434921264648\n",
      "Epoch 42/200, Loss: 1.5002416372299194\n",
      "Epoch 43/200, Loss: 1.2292860746383667\n",
      "Epoch 44/200, Loss: 1.3841496706008911\n",
      "Epoch 45/200, Loss: 1.1722239255905151\n",
      "Epoch 46/200, Loss: 1.4925615787506104\n",
      "Epoch 47/200, Loss: 1.0573523044586182\n",
      "Epoch 48/200, Loss: 1.5154505968093872\n",
      "Epoch 49/200, Loss: 1.364823818206787\n",
      "Epoch 50/200, Loss: 1.5325653553009033\n",
      "Epoch 51/200, Loss: 0.7320559620857239\n",
      "Epoch 52/200, Loss: 1.6540511846542358\n",
      "Epoch 53/200, Loss: 1.55504310131073\n",
      "Epoch 54/200, Loss: 1.1418302059173584\n",
      "Epoch 55/200, Loss: 1.1437984704971313\n",
      "Epoch 56/200, Loss: 1.4897961616516113\n",
      "Epoch 57/200, Loss: 1.1674492359161377\n",
      "Epoch 58/200, Loss: 1.455280065536499\n",
      "Epoch 59/200, Loss: 1.155074954032898\n",
      "Epoch 60/200, Loss: 1.2119897603988647\n",
      "Epoch 61/200, Loss: 1.1854331493377686\n",
      "Epoch 62/200, Loss: 0.9673096537590027\n",
      "Epoch 63/200, Loss: 1.275050401687622\n",
      "Epoch 64/200, Loss: 1.3454773426055908\n",
      "Epoch 65/200, Loss: 1.3735759258270264\n",
      "Epoch 66/200, Loss: 1.2580773830413818\n",
      "Epoch 67/200, Loss: 1.8553829193115234\n",
      "Epoch 68/200, Loss: 1.197421669960022\n",
      "Epoch 69/200, Loss: 0.8858903646469116\n",
      "Epoch 70/200, Loss: 0.8748464584350586\n",
      "Epoch 71/200, Loss: 0.6337441205978394\n",
      "Epoch 72/200, Loss: 1.206314206123352\n",
      "Epoch 73/200, Loss: 0.8042279481887817\n",
      "Epoch 74/200, Loss: 1.1694711446762085\n",
      "Epoch 75/200, Loss: 0.9511995315551758\n",
      "Epoch 76/200, Loss: 0.8094117045402527\n",
      "Epoch 77/200, Loss: 1.3969578742980957\n",
      "Epoch 78/200, Loss: 1.5670497417449951\n",
      "Epoch 79/200, Loss: 1.546789526939392\n",
      "Epoch 80/200, Loss: 0.9211094975471497\n",
      "Epoch 81/200, Loss: 0.7165426015853882\n",
      "Epoch 82/200, Loss: 1.2852280139923096\n",
      "Epoch 83/200, Loss: 1.0649125576019287\n",
      "Epoch 84/200, Loss: 0.8250934481620789\n",
      "Epoch 85/200, Loss: 1.2829124927520752\n",
      "Epoch 86/200, Loss: 1.421248197555542\n",
      "Epoch 87/200, Loss: 1.0153563022613525\n",
      "Epoch 88/200, Loss: 1.0505883693695068\n",
      "Epoch 89/200, Loss: 1.532061219215393\n",
      "Epoch 90/200, Loss: 1.1784205436706543\n",
      "Epoch 91/200, Loss: 0.7648942470550537\n",
      "Epoch 92/200, Loss: 1.1719515323638916\n",
      "Epoch 93/200, Loss: 1.4422681331634521\n",
      "Epoch 94/200, Loss: 0.9070928692817688\n",
      "Epoch 95/200, Loss: 0.8844178915023804\n",
      "Epoch 96/200, Loss: 1.0130778551101685\n",
      "Epoch 97/200, Loss: 1.3330409526824951\n",
      "Epoch 98/200, Loss: 1.0080935955047607\n",
      "Epoch 99/200, Loss: 0.6794169545173645\n",
      "Epoch 100/200, Loss: 0.9527873992919922\n",
      "Epoch 101/200, Loss: 0.7754050493240356\n",
      "Epoch 102/200, Loss: 0.5174975991249084\n",
      "Epoch 103/200, Loss: 1.2133746147155762\n",
      "Epoch 104/200, Loss: 1.8276923894882202\n",
      "Epoch 105/200, Loss: 0.6727025508880615\n",
      "Epoch 106/200, Loss: 0.6678398251533508\n",
      "Epoch 107/200, Loss: 1.3946611881256104\n",
      "Epoch 108/200, Loss: 0.6680353283882141\n",
      "Epoch 109/200, Loss: 1.4202494621276855\n",
      "Epoch 110/200, Loss: 0.6067007780075073\n",
      "Epoch 111/200, Loss: 1.9027057886123657\n",
      "Epoch 112/200, Loss: 0.9499678611755371\n",
      "Epoch 113/200, Loss: 0.5465565919876099\n",
      "Epoch 114/200, Loss: 0.6540836095809937\n",
      "Epoch 115/200, Loss: 1.6855329275131226\n",
      "Epoch 116/200, Loss: 1.287321925163269\n",
      "Epoch 117/200, Loss: 0.9979904294013977\n",
      "Epoch 118/200, Loss: 1.0766363143920898\n",
      "Epoch 119/200, Loss: 0.7635807991027832\n",
      "Epoch 120/200, Loss: 1.1232367753982544\n",
      "Epoch 121/200, Loss: 0.93853360414505\n",
      "Epoch 122/200, Loss: 0.9923712015151978\n",
      "Epoch 123/200, Loss: 0.7965947985649109\n",
      "Epoch 124/200, Loss: 0.5638006329536438\n",
      "Epoch 125/200, Loss: 0.8194648027420044\n",
      "Epoch 126/200, Loss: 0.9745559692382812\n",
      "Epoch 127/200, Loss: 0.8167037963867188\n",
      "Epoch 128/200, Loss: 1.222906231880188\n",
      "Epoch 129/200, Loss: 1.1506917476654053\n",
      "Epoch 130/200, Loss: 0.2849777340888977\n",
      "Epoch 131/200, Loss: 0.4399852752685547\n",
      "Epoch 132/200, Loss: 0.8380008935928345\n",
      "Epoch 133/200, Loss: 0.8034390211105347\n",
      "Epoch 134/200, Loss: 0.610794723033905\n",
      "Epoch 135/200, Loss: 0.6209204196929932\n",
      "Epoch 136/200, Loss: 1.1167818307876587\n",
      "Epoch 137/200, Loss: 0.7426262497901917\n",
      "Epoch 138/200, Loss: 0.8007944822311401\n",
      "Epoch 139/200, Loss: 0.2276579886674881\n",
      "Epoch 140/200, Loss: 0.633346438407898\n",
      "Epoch 141/200, Loss: 0.3047742247581482\n",
      "Epoch 142/200, Loss: 0.7060808539390564\n",
      "Epoch 143/200, Loss: 0.40751323103904724\n",
      "Epoch 144/200, Loss: 0.924848735332489\n",
      "Epoch 145/200, Loss: 1.8275476694107056\n",
      "Epoch 146/200, Loss: 1.220805048942566\n",
      "Epoch 147/200, Loss: 1.0054055452346802\n",
      "Epoch 148/200, Loss: 1.2020323276519775\n",
      "Epoch 149/200, Loss: 0.9415658712387085\n",
      "Epoch 150/200, Loss: 0.2598791718482971\n",
      "Epoch 151/200, Loss: 1.2134559154510498\n",
      "Epoch 152/200, Loss: 1.0026119947433472\n",
      "Epoch 153/200, Loss: 0.5329312682151794\n",
      "Epoch 154/200, Loss: 0.8580682873725891\n",
      "Epoch 155/200, Loss: 0.9366079568862915\n",
      "Epoch 156/200, Loss: 0.6258865594863892\n",
      "Epoch 157/200, Loss: 1.1563849449157715\n",
      "Epoch 158/200, Loss: 0.647861659526825\n",
      "Epoch 159/200, Loss: 0.7111879587173462\n",
      "Epoch 160/200, Loss: 0.7310165166854858\n",
      "Epoch 161/200, Loss: 0.6588714718818665\n",
      "Epoch 162/200, Loss: 0.31902971863746643\n",
      "Epoch 163/200, Loss: 0.2606349289417267\n",
      "Epoch 164/200, Loss: 0.5629128217697144\n",
      "Epoch 165/200, Loss: 0.7340517640113831\n",
      "Epoch 166/200, Loss: 0.17239835858345032\n",
      "Epoch 167/200, Loss: 0.5921369194984436\n",
      "Epoch 168/200, Loss: 2.977513313293457\n",
      "Epoch 169/200, Loss: 1.0311009883880615\n",
      "Epoch 170/200, Loss: 1.1334962844848633\n",
      "Epoch 171/200, Loss: 0.8727712631225586\n",
      "Epoch 172/200, Loss: 0.9217398762702942\n",
      "Epoch 173/200, Loss: 0.46054816246032715\n",
      "Epoch 174/200, Loss: 1.9695613384246826\n",
      "Epoch 175/200, Loss: 1.083575963973999\n",
      "Epoch 176/200, Loss: 0.8525754809379578\n",
      "Epoch 177/200, Loss: 1.3904753923416138\n",
      "Epoch 178/200, Loss: 1.0020053386688232\n",
      "Epoch 179/200, Loss: 1.7100436687469482\n",
      "Epoch 180/200, Loss: 1.65192449092865\n",
      "Epoch 181/200, Loss: 1.4812721014022827\n",
      "Epoch 182/200, Loss: 0.9624991416931152\n",
      "Epoch 183/200, Loss: 0.5891643762588501\n",
      "Epoch 184/200, Loss: 0.5193009972572327\n",
      "Epoch 185/200, Loss: 0.9458640217781067\n",
      "Epoch 186/200, Loss: 1.9638550281524658\n",
      "Epoch 187/200, Loss: 0.6229613423347473\n",
      "Epoch 188/200, Loss: 0.7954917550086975\n",
      "Epoch 189/200, Loss: 0.7091500163078308\n",
      "Epoch 190/200, Loss: 0.49323540925979614\n",
      "Epoch 191/200, Loss: 0.6006690263748169\n",
      "Epoch 192/200, Loss: 0.08165234327316284\n",
      "Epoch 193/200, Loss: 0.7473772764205933\n",
      "Epoch 194/200, Loss: 1.196021318435669\n",
      "Epoch 195/200, Loss: 0.6064047813415527\n",
      "Epoch 196/200, Loss: 0.8517807722091675\n",
      "Epoch 197/200, Loss: 0.6914695501327515\n",
      "Epoch 198/200, Loss: 1.1135457754135132\n",
      "Epoch 199/200, Loss: 1.0584795475006104\n",
      "Epoch 200/200, Loss: 0.9952560663223267\n",
      "Accuracy: 55.55555555555556%\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-5', clean_root_dir='Sequences/clean', model_path='alter5_non_binary_model.pth',is_binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PoisonDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 5.123922348022461\n",
      "Epoch 2/200, Loss: 11.149568557739258\n",
      "Epoch 3/200, Loss: 5.0577592849731445\n",
      "Epoch 4/200, Loss: 0.8559304475784302\n",
      "Epoch 5/200, Loss: 1.710465669631958\n",
      "Epoch 6/200, Loss: 4.042398929595947\n",
      "Epoch 7/200, Loss: 3.9309589862823486\n",
      "Epoch 8/200, Loss: 3.938809871673584\n",
      "Epoch 9/200, Loss: 5.895794868469238\n",
      "Epoch 10/200, Loss: 6.800595760345459\n",
      "Epoch 11/200, Loss: 2.4453890323638916\n",
      "Epoch 12/200, Loss: 4.938717365264893\n",
      "Epoch 13/200, Loss: 4.212235927581787\n",
      "Epoch 14/200, Loss: 3.3438820838928223\n",
      "Epoch 15/200, Loss: 2.5199761390686035\n",
      "Epoch 16/200, Loss: 3.3823909759521484\n",
      "Epoch 17/200, Loss: 1.1964057683944702\n",
      "Epoch 18/200, Loss: 1.522032618522644\n",
      "Epoch 19/200, Loss: 3.0729947090148926\n",
      "Epoch 20/200, Loss: 4.55666971206665\n",
      "Epoch 21/200, Loss: 2.239671230316162\n",
      "Epoch 22/200, Loss: 4.287697792053223\n",
      "Epoch 23/200, Loss: 4.705223083496094\n",
      "Epoch 24/200, Loss: 1.6584055423736572\n",
      "Epoch 25/200, Loss: 1.4008771181106567\n",
      "Epoch 26/200, Loss: 1.6024404764175415\n",
      "Epoch 27/200, Loss: 6.676477909088135\n",
      "Epoch 28/200, Loss: 3.7858738899230957\n",
      "Epoch 29/200, Loss: 0.34297487139701843\n",
      "Epoch 30/200, Loss: 3.791353225708008\n",
      "Epoch 31/200, Loss: 4.103772163391113\n",
      "Epoch 32/200, Loss: 2.2328927516937256\n",
      "Epoch 33/200, Loss: 4.477610111236572\n",
      "Epoch 34/200, Loss: 2.8181512355804443\n",
      "Epoch 35/200, Loss: 3.560460329055786\n",
      "Epoch 36/200, Loss: 7.59070348739624\n",
      "Epoch 37/200, Loss: 1.6782493591308594\n",
      "Epoch 38/200, Loss: 2.848841428756714\n",
      "Epoch 39/200, Loss: 1.0211756229400635\n",
      "Epoch 40/200, Loss: 0.309761106967926\n",
      "Epoch 41/200, Loss: 2.059173583984375\n",
      "Epoch 42/200, Loss: 1.6928914785385132\n",
      "Epoch 43/200, Loss: 4.185326099395752\n",
      "Epoch 44/200, Loss: 2.4208598136901855\n",
      "Epoch 45/200, Loss: 3.106292724609375\n",
      "Epoch 46/200, Loss: 2.743727445602417\n",
      "Epoch 47/200, Loss: 1.649979829788208\n",
      "Epoch 48/200, Loss: 0.35035595297813416\n",
      "Epoch 49/200, Loss: 1.8248369693756104\n",
      "Epoch 50/200, Loss: 4.458803176879883\n",
      "Epoch 51/200, Loss: 0.27529317140579224\n",
      "Epoch 52/200, Loss: 2.5366051197052\n",
      "Epoch 53/200, Loss: 4.62583589553833\n",
      "Epoch 54/200, Loss: 0.9647027850151062\n",
      "Epoch 55/200, Loss: 2.0354435443878174\n",
      "Epoch 56/200, Loss: 2.1116418838500977\n",
      "Epoch 57/200, Loss: 1.6960041522979736\n",
      "Epoch 58/200, Loss: 1.0638749599456787\n",
      "Epoch 59/200, Loss: 1.6534936428070068\n",
      "Epoch 60/200, Loss: 2.2187740802764893\n",
      "Epoch 61/200, Loss: 2.275468587875366\n",
      "Epoch 62/200, Loss: 3.5946121215820312\n",
      "Epoch 63/200, Loss: 1.303844690322876\n",
      "Epoch 64/200, Loss: 0.9632444381713867\n",
      "Epoch 65/200, Loss: 1.727081537246704\n",
      "Epoch 66/200, Loss: 1.1621586084365845\n",
      "Epoch 67/200, Loss: 0.6447867155075073\n",
      "Epoch 68/200, Loss: 1.5560426712036133\n",
      "Epoch 69/200, Loss: 1.269775629043579\n",
      "Epoch 70/200, Loss: 3.2617459297180176\n",
      "Epoch 71/200, Loss: 5.23140287399292\n",
      "Epoch 72/200, Loss: 3.018254518508911\n",
      "Epoch 73/200, Loss: 2.040820360183716\n",
      "Epoch 74/200, Loss: 7.346518039703369\n",
      "Epoch 75/200, Loss: 0.801680862903595\n",
      "Epoch 76/200, Loss: 1.185716986656189\n",
      "Epoch 77/200, Loss: 1.459596037864685\n",
      "Epoch 78/200, Loss: 0.5299327373504639\n",
      "Epoch 79/200, Loss: 2.5522513389587402\n",
      "Epoch 80/200, Loss: 0.7403121590614319\n",
      "Epoch 81/200, Loss: 1.0622094869613647\n",
      "Epoch 82/200, Loss: 1.0037846565246582\n",
      "Epoch 83/200, Loss: 1.1238536834716797\n",
      "Epoch 84/200, Loss: 1.4056477546691895\n",
      "Epoch 85/200, Loss: 0.863143801689148\n",
      "Epoch 86/200, Loss: 0.5404752492904663\n",
      "Epoch 87/200, Loss: 0.3554152548313141\n",
      "Epoch 88/200, Loss: 0.29224568605422974\n",
      "Epoch 89/200, Loss: 1.1794230937957764\n",
      "Epoch 90/200, Loss: 1.2795689105987549\n",
      "Epoch 91/200, Loss: 0.6359217166900635\n",
      "Epoch 92/200, Loss: 0.5984971523284912\n",
      "Epoch 93/200, Loss: 0.7700774669647217\n",
      "Epoch 94/200, Loss: 0.8353557586669922\n",
      "Epoch 95/200, Loss: 0.6504188179969788\n",
      "Epoch 96/200, Loss: 0.4501265585422516\n",
      "Epoch 97/200, Loss: 0.39572665095329285\n",
      "Epoch 98/200, Loss: 0.3428991436958313\n",
      "Epoch 99/200, Loss: 0.524006187915802\n",
      "Epoch 100/200, Loss: 0.09955370426177979\n",
      "Epoch 101/200, Loss: 0.27534276247024536\n",
      "Epoch 102/200, Loss: 1.5785249471664429\n",
      "Epoch 103/200, Loss: 0.9186406135559082\n",
      "Epoch 104/200, Loss: 0.08053676038980484\n",
      "Epoch 105/200, Loss: 0.5563700199127197\n",
      "Epoch 106/200, Loss: 0.7675306797027588\n",
      "Epoch 107/200, Loss: 0.5310337543487549\n",
      "Epoch 108/200, Loss: 0.07058648020029068\n",
      "Epoch 109/200, Loss: 0.3480796217918396\n",
      "Epoch 110/200, Loss: 0.08530224859714508\n",
      "Epoch 111/200, Loss: 1.0395275354385376\n",
      "Epoch 112/200, Loss: 0.393657386302948\n",
      "Epoch 113/200, Loss: 0.29186275601387024\n",
      "Epoch 114/200, Loss: 0.366026371717453\n",
      "Epoch 115/200, Loss: 0.5430442094802856\n",
      "Epoch 116/200, Loss: 0.5042452216148376\n",
      "Epoch 117/200, Loss: 0.18527773022651672\n",
      "Epoch 118/200, Loss: 0.6019549369812012\n",
      "Epoch 119/200, Loss: 0.8243365287780762\n",
      "Epoch 120/200, Loss: 0.39892417192459106\n",
      "Epoch 121/200, Loss: 0.5490109324455261\n",
      "Epoch 122/200, Loss: 0.2497442215681076\n",
      "Epoch 123/200, Loss: 0.1819770783185959\n",
      "Epoch 124/200, Loss: 0.09457510709762573\n",
      "Epoch 125/200, Loss: 0.5451072454452515\n",
      "Epoch 126/200, Loss: 0.269330233335495\n",
      "Epoch 127/200, Loss: 5.763102054595947\n",
      "Epoch 128/200, Loss: 4.006464958190918\n",
      "Epoch 129/200, Loss: 0.61371248960495\n",
      "Epoch 130/200, Loss: 0.9365836977958679\n",
      "Epoch 131/200, Loss: 0.044616151601076126\n",
      "Epoch 132/200, Loss: 1.6741005182266235\n",
      "Epoch 133/200, Loss: 0.3533196449279785\n",
      "Epoch 134/200, Loss: 2.085042953491211\n",
      "Epoch 135/200, Loss: 0.9437535405158997\n",
      "Epoch 136/200, Loss: 1.9302327632904053\n",
      "Epoch 137/200, Loss: 1.3268413543701172\n",
      "Epoch 138/200, Loss: 4.372631549835205\n",
      "Epoch 139/200, Loss: 2.2446718215942383\n",
      "Epoch 140/200, Loss: 1.982163429260254\n",
      "Epoch 141/200, Loss: 0.7778919339179993\n",
      "Epoch 142/200, Loss: 1.1847163438796997\n",
      "Epoch 143/200, Loss: 1.555083990097046\n",
      "Epoch 144/200, Loss: 0.5372219085693359\n",
      "Epoch 145/200, Loss: 0.6665869951248169\n",
      "Epoch 146/200, Loss: 0.446051687002182\n",
      "Epoch 147/200, Loss: 0.1668362319469452\n",
      "Epoch 148/200, Loss: 1.3168532848358154\n",
      "Epoch 149/200, Loss: 0.8845488429069519\n",
      "Epoch 150/200, Loss: 0.32120823860168457\n",
      "Epoch 151/200, Loss: 1.1175613403320312\n",
      "Epoch 152/200, Loss: 1.4788858890533447\n",
      "Epoch 153/200, Loss: 0.3526914417743683\n",
      "Epoch 154/200, Loss: 0.7681796550750732\n",
      "Epoch 155/200, Loss: 1.4386157989501953\n",
      "Epoch 156/200, Loss: 0.6048756837844849\n",
      "Epoch 157/200, Loss: 1.2041096687316895\n",
      "Epoch 158/200, Loss: 0.4504469037055969\n",
      "Epoch 159/200, Loss: 0.7032895684242249\n",
      "Epoch 160/200, Loss: 1.660692572593689\n",
      "Epoch 161/200, Loss: 1.341833233833313\n",
      "Epoch 162/200, Loss: 0.08812849223613739\n",
      "Epoch 163/200, Loss: 1.0178487300872803\n",
      "Epoch 164/200, Loss: 0.2785789370536804\n",
      "Epoch 165/200, Loss: 0.2500097155570984\n",
      "Epoch 166/200, Loss: 0.38416534662246704\n",
      "Epoch 167/200, Loss: 0.3499200940132141\n",
      "Epoch 168/200, Loss: 0.9747095108032227\n",
      "Epoch 169/200, Loss: 0.04858412593603134\n",
      "Epoch 170/200, Loss: 0.5666834712028503\n",
      "Epoch 171/200, Loss: 1.00392484664917\n",
      "Epoch 172/200, Loss: 0.6937216520309448\n",
      "Epoch 173/200, Loss: 0.6050367951393127\n",
      "Epoch 174/200, Loss: 0.7061368823051453\n",
      "Epoch 175/200, Loss: 0.9873577952384949\n",
      "Epoch 176/200, Loss: 0.24075965583324432\n",
      "Epoch 177/200, Loss: 0.11715897172689438\n",
      "Epoch 178/200, Loss: 0.05189557000994682\n",
      "Epoch 179/200, Loss: 1.1347211599349976\n",
      "Epoch 180/200, Loss: 0.0769030973315239\n",
      "Epoch 181/200, Loss: 0.2650623917579651\n",
      "Epoch 182/200, Loss: 0.06818042695522308\n",
      "Epoch 183/200, Loss: 0.6341627836227417\n",
      "Epoch 184/200, Loss: 0.23108837008476257\n",
      "Epoch 185/200, Loss: 0.26714402437210083\n",
      "Epoch 186/200, Loss: 1.1428301334381104\n",
      "Epoch 187/200, Loss: 0.2404974400997162\n",
      "Epoch 188/200, Loss: 0.046882037073373795\n",
      "Epoch 189/200, Loss: 0.3904160261154175\n",
      "Epoch 190/200, Loss: 3.287202835083008\n",
      "Epoch 191/200, Loss: 9.412320137023926\n",
      "Epoch 192/200, Loss: 4.952704906463623\n",
      "Epoch 193/200, Loss: 2.6744532585144043\n",
      "Epoch 194/200, Loss: 7.9437384605407715\n",
      "Epoch 195/200, Loss: 1.1050622463226318\n",
      "Epoch 196/200, Loss: 1.9264678955078125\n",
      "Epoch 197/200, Loss: 1.1464722156524658\n",
      "Epoch 198/200, Loss: 1.7868314981460571\n",
      "Epoch 199/200, Loss: 3.4123313426971436\n",
      "Epoch 200/200, Loss: 2.485888719558716\n",
      "MSE: 2.6114982234107122\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/adversarial', clean_root_dir='Sequences/clean', model_path='non_binary_model.pth',is_binary=False, is_regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 3.416579484939575\n",
      "Epoch 2/200, Loss: 4.307740688323975\n",
      "Epoch 3/200, Loss: 3.2827541828155518\n",
      "Epoch 4/200, Loss: 5.515273094177246\n",
      "Epoch 5/200, Loss: 2.6254615783691406\n",
      "Epoch 6/200, Loss: 1.23464834690094\n",
      "Epoch 7/200, Loss: 4.6255574226379395\n",
      "Epoch 8/200, Loss: 8.075296401977539\n",
      "Epoch 9/200, Loss: 2.8362231254577637\n",
      "Epoch 10/200, Loss: 1.2456380128860474\n",
      "Epoch 11/200, Loss: 9.775550842285156\n",
      "Epoch 12/200, Loss: 4.544541358947754\n",
      "Epoch 13/200, Loss: 2.3222460746765137\n",
      "Epoch 14/200, Loss: 3.630547285079956\n",
      "Epoch 15/200, Loss: 0.8914348483085632\n",
      "Epoch 16/200, Loss: 2.8769919872283936\n",
      "Epoch 17/200, Loss: 5.039581298828125\n",
      "Epoch 18/200, Loss: 6.772791862487793\n",
      "Epoch 19/200, Loss: 3.8486971855163574\n",
      "Epoch 20/200, Loss: 2.78110933303833\n",
      "Epoch 21/200, Loss: 3.5124459266662598\n",
      "Epoch 22/200, Loss: 2.499272108078003\n",
      "Epoch 23/200, Loss: 2.1864311695098877\n",
      "Epoch 24/200, Loss: 3.359081745147705\n",
      "Epoch 25/200, Loss: 1.5611207485198975\n",
      "Epoch 26/200, Loss: 2.0318238735198975\n",
      "Epoch 27/200, Loss: 1.9049936532974243\n",
      "Epoch 28/200, Loss: 4.265715599060059\n",
      "Epoch 29/200, Loss: 1.8825603723526\n",
      "Epoch 30/200, Loss: 1.8848888874053955\n",
      "Epoch 31/200, Loss: 5.6599931716918945\n",
      "Epoch 32/200, Loss: 4.0015716552734375\n",
      "Epoch 33/200, Loss: 1.9409996271133423\n",
      "Epoch 34/200, Loss: 1.9744765758514404\n",
      "Epoch 35/200, Loss: 5.2079596519470215\n",
      "Epoch 36/200, Loss: 3.2375271320343018\n",
      "Epoch 37/200, Loss: 3.9523117542266846\n",
      "Epoch 38/200, Loss: 2.772841453552246\n",
      "Epoch 39/200, Loss: 4.344126224517822\n",
      "Epoch 40/200, Loss: 7.263760566711426\n",
      "Epoch 41/200, Loss: 3.777925968170166\n",
      "Epoch 42/200, Loss: 5.729681491851807\n",
      "Epoch 43/200, Loss: 10.684648513793945\n",
      "Epoch 44/200, Loss: 4.401918888092041\n",
      "Epoch 45/200, Loss: 0.6294280886650085\n",
      "Epoch 46/200, Loss: 0.5326617360115051\n",
      "Epoch 47/200, Loss: 5.912161827087402\n",
      "Epoch 48/200, Loss: 3.5868263244628906\n",
      "Epoch 49/200, Loss: 2.361586809158325\n",
      "Epoch 50/200, Loss: 2.871633529663086\n",
      "Epoch 51/200, Loss: 2.3732779026031494\n",
      "Epoch 52/200, Loss: 3.255835771560669\n",
      "Epoch 53/200, Loss: 2.1824514865875244\n",
      "Epoch 54/200, Loss: 3.7700905799865723\n",
      "Epoch 55/200, Loss: 2.3150739669799805\n",
      "Epoch 56/200, Loss: 1.1392682790756226\n",
      "Epoch 57/200, Loss: 3.0476458072662354\n",
      "Epoch 58/200, Loss: 6.120283603668213\n",
      "Epoch 59/200, Loss: 0.5119303464889526\n",
      "Epoch 60/200, Loss: 1.517115831375122\n",
      "Epoch 61/200, Loss: 2.769106388092041\n",
      "Epoch 62/200, Loss: 4.043038368225098\n",
      "Epoch 63/200, Loss: 4.567065715789795\n",
      "Epoch 64/200, Loss: 0.9070594906806946\n",
      "Epoch 65/200, Loss: 3.9597268104553223\n",
      "Epoch 66/200, Loss: 2.0570290088653564\n",
      "Epoch 67/200, Loss: 2.1601011753082275\n",
      "Epoch 68/200, Loss: 5.2438578605651855\n",
      "Epoch 69/200, Loss: 1.5496233701705933\n",
      "Epoch 70/200, Loss: 3.719895601272583\n",
      "Epoch 71/200, Loss: 1.6983722448349\n",
      "Epoch 72/200, Loss: 1.781593680381775\n",
      "Epoch 73/200, Loss: 2.7531681060791016\n",
      "Epoch 74/200, Loss: 8.581241607666016\n",
      "Epoch 75/200, Loss: 8.609094619750977\n",
      "Epoch 76/200, Loss: 2.287532329559326\n",
      "Epoch 77/200, Loss: 3.1422197818756104\n",
      "Epoch 78/200, Loss: 3.3328545093536377\n",
      "Epoch 79/200, Loss: 2.295685291290283\n",
      "Epoch 80/200, Loss: 1.373383641242981\n",
      "Epoch 81/200, Loss: 3.4060161113739014\n",
      "Epoch 82/200, Loss: 2.554757595062256\n",
      "Epoch 83/200, Loss: 1.1714198589324951\n",
      "Epoch 84/200, Loss: 0.9990959167480469\n",
      "Epoch 85/200, Loss: 1.9794585704803467\n",
      "Epoch 86/200, Loss: 5.695725917816162\n",
      "Epoch 87/200, Loss: 3.391599655151367\n",
      "Epoch 88/200, Loss: 2.135723352432251\n",
      "Epoch 89/200, Loss: 5.130239486694336\n",
      "Epoch 90/200, Loss: 4.2697367668151855\n",
      "Epoch 91/200, Loss: 2.3305435180664062\n",
      "Epoch 92/200, Loss: 6.7055344581604\n",
      "Epoch 93/200, Loss: 3.0083041191101074\n",
      "Epoch 94/200, Loss: 4.912567615509033\n",
      "Epoch 95/200, Loss: 1.7324384450912476\n",
      "Epoch 96/200, Loss: 1.2711375951766968\n",
      "Epoch 97/200, Loss: 1.527080774307251\n",
      "Epoch 98/200, Loss: 3.7085392475128174\n",
      "Epoch 99/200, Loss: 5.230792999267578\n",
      "Epoch 100/200, Loss: 0.683800995349884\n",
      "Epoch 101/200, Loss: 3.7529373168945312\n",
      "Epoch 102/200, Loss: 3.6826698780059814\n",
      "Epoch 103/200, Loss: 1.0055782794952393\n",
      "Epoch 104/200, Loss: 4.98407506942749\n",
      "Epoch 105/200, Loss: 3.421184539794922\n",
      "Epoch 106/200, Loss: 2.6853373050689697\n",
      "Epoch 107/200, Loss: 4.887038230895996\n",
      "Epoch 108/200, Loss: 4.558018207550049\n",
      "Epoch 109/200, Loss: 4.903679847717285\n",
      "Epoch 110/200, Loss: 1.4931442737579346\n",
      "Epoch 111/200, Loss: 0.9680845141410828\n",
      "Epoch 112/200, Loss: 1.2543295621871948\n",
      "Epoch 113/200, Loss: 2.423396587371826\n",
      "Epoch 114/200, Loss: 6.3520307540893555\n",
      "Epoch 115/200, Loss: 2.0664072036743164\n",
      "Epoch 116/200, Loss: 1.044262170791626\n",
      "Epoch 117/200, Loss: 4.272887229919434\n",
      "Epoch 118/200, Loss: 4.128218650817871\n",
      "Epoch 119/200, Loss: 3.396146774291992\n",
      "Epoch 120/200, Loss: 3.213460922241211\n",
      "Epoch 121/200, Loss: 4.034317493438721\n",
      "Epoch 122/200, Loss: 2.29436993598938\n",
      "Epoch 123/200, Loss: 6.332935333251953\n",
      "Epoch 124/200, Loss: 6.6451616287231445\n",
      "Epoch 125/200, Loss: 2.6569533348083496\n",
      "Epoch 126/200, Loss: 2.944093942642212\n",
      "Epoch 127/200, Loss: 3.0788722038269043\n",
      "Epoch 128/200, Loss: 1.2902538776397705\n",
      "Epoch 129/200, Loss: 9.432035446166992\n",
      "Epoch 130/200, Loss: 2.224255084991455\n",
      "Epoch 131/200, Loss: 2.673398494720459\n",
      "Epoch 132/200, Loss: 3.277524471282959\n",
      "Epoch 133/200, Loss: 6.479272365570068\n",
      "Epoch 134/200, Loss: 4.144309043884277\n",
      "Epoch 135/200, Loss: 9.493130683898926\n",
      "Epoch 136/200, Loss: 7.830641269683838\n",
      "Epoch 137/200, Loss: 0.7751350402832031\n",
      "Epoch 138/200, Loss: 2.4627737998962402\n",
      "Epoch 139/200, Loss: 6.000843048095703\n",
      "Epoch 140/200, Loss: 4.0528059005737305\n",
      "Epoch 141/200, Loss: 3.942847490310669\n",
      "Epoch 142/200, Loss: 4.658719062805176\n",
      "Epoch 143/200, Loss: 4.018414497375488\n",
      "Epoch 144/200, Loss: 3.5408127307891846\n",
      "Epoch 145/200, Loss: 1.8474477529525757\n",
      "Epoch 146/200, Loss: 4.055933952331543\n",
      "Epoch 147/200, Loss: 3.804063081741333\n",
      "Epoch 148/200, Loss: 1.3633852005004883\n",
      "Epoch 149/200, Loss: 2.2446353435516357\n",
      "Epoch 150/200, Loss: 2.6769556999206543\n",
      "Epoch 151/200, Loss: 1.6225115060806274\n",
      "Epoch 152/200, Loss: 3.745638370513916\n",
      "Epoch 153/200, Loss: 6.779062747955322\n",
      "Epoch 154/200, Loss: 3.691260814666748\n",
      "Epoch 155/200, Loss: 1.1649060249328613\n",
      "Epoch 156/200, Loss: 3.2704594135284424\n",
      "Epoch 157/200, Loss: 2.688756227493286\n",
      "Epoch 158/200, Loss: 2.233314037322998\n",
      "Epoch 159/200, Loss: 10.232725143432617\n",
      "Epoch 160/200, Loss: 3.6945502758026123\n",
      "Epoch 161/200, Loss: 3.6037468910217285\n",
      "Epoch 162/200, Loss: 5.7403645515441895\n",
      "Epoch 163/200, Loss: 3.8935933113098145\n",
      "Epoch 164/200, Loss: 0.767635703086853\n",
      "Epoch 165/200, Loss: 5.424217224121094\n",
      "Epoch 166/200, Loss: 8.472646713256836\n",
      "Epoch 167/200, Loss: 1.784406304359436\n",
      "Epoch 168/200, Loss: 0.6041792035102844\n",
      "Epoch 169/200, Loss: 3.225721836090088\n",
      "Epoch 170/200, Loss: 2.673705577850342\n",
      "Epoch 171/200, Loss: 3.8440334796905518\n",
      "Epoch 172/200, Loss: 4.368882656097412\n",
      "Epoch 173/200, Loss: 2.8098244667053223\n",
      "Epoch 174/200, Loss: 4.496638298034668\n",
      "Epoch 175/200, Loss: 1.5110713243484497\n",
      "Epoch 176/200, Loss: 2.224388837814331\n",
      "Epoch 177/200, Loss: 4.364804267883301\n",
      "Epoch 178/200, Loss: 1.6936790943145752\n",
      "Epoch 179/200, Loss: 4.457836151123047\n",
      "Epoch 180/200, Loss: 1.7968298196792603\n",
      "Epoch 181/200, Loss: 2.0790224075317383\n",
      "Epoch 182/200, Loss: 2.069401264190674\n",
      "Epoch 183/200, Loss: 4.513916015625\n",
      "Epoch 184/200, Loss: 2.3382318019866943\n",
      "Epoch 185/200, Loss: 2.999110221862793\n",
      "Epoch 186/200, Loss: 1.0696851015090942\n",
      "Epoch 187/200, Loss: 1.4316096305847168\n",
      "Epoch 188/200, Loss: 1.0364880561828613\n",
      "Epoch 189/200, Loss: 3.2828586101531982\n",
      "Epoch 190/200, Loss: 3.5707974433898926\n",
      "Epoch 191/200, Loss: 0.24733948707580566\n",
      "Epoch 192/200, Loss: 1.9004173278808594\n",
      "Epoch 193/200, Loss: 2.0184061527252197\n",
      "Epoch 194/200, Loss: 2.2365026473999023\n",
      "Epoch 195/200, Loss: 2.4988465309143066\n",
      "Epoch 196/200, Loss: 3.6193816661834717\n",
      "Epoch 197/200, Loss: 1.5935475826263428\n",
      "Epoch 198/200, Loss: 1.9803158044815063\n",
      "Epoch 199/200, Loss: 2.415482997894287\n",
      "Epoch 200/200, Loss: 3.998072862625122\n",
      "MSE: 2.6717691818873086\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-2', clean_root_dir='Sequences/clean', model_path='alter2_non_binary_model_reg.pth',is_binary=False, is_regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 8.182415962219238\n",
      "Epoch 2/200, Loss: 4.70328426361084\n",
      "Epoch 3/200, Loss: 5.2111310958862305\n",
      "Epoch 4/200, Loss: 2.4324252605438232\n",
      "Epoch 5/200, Loss: 8.462702751159668\n",
      "Epoch 6/200, Loss: 7.383087158203125\n",
      "Epoch 7/200, Loss: 0.5631847381591797\n",
      "Epoch 8/200, Loss: 5.988704681396484\n",
      "Epoch 9/200, Loss: 3.6635901927948\n",
      "Epoch 10/200, Loss: 4.873634338378906\n",
      "Epoch 11/200, Loss: 8.763437271118164\n",
      "Epoch 12/200, Loss: 7.4235429763793945\n",
      "Epoch 13/200, Loss: 10.602694511413574\n",
      "Epoch 14/200, Loss: 1.824698805809021\n",
      "Epoch 15/200, Loss: 2.4697234630584717\n",
      "Epoch 16/200, Loss: 4.190909385681152\n",
      "Epoch 17/200, Loss: 2.4968676567077637\n",
      "Epoch 18/200, Loss: 3.2347896099090576\n",
      "Epoch 19/200, Loss: 1.9241317510604858\n",
      "Epoch 20/200, Loss: 5.555987358093262\n",
      "Epoch 21/200, Loss: 2.9950897693634033\n",
      "Epoch 22/200, Loss: 6.588841438293457\n",
      "Epoch 23/200, Loss: 3.6336941719055176\n",
      "Epoch 24/200, Loss: 4.821601390838623\n",
      "Epoch 25/200, Loss: 5.711309909820557\n",
      "Epoch 26/200, Loss: 2.8721132278442383\n",
      "Epoch 27/200, Loss: 4.866671562194824\n",
      "Epoch 28/200, Loss: 6.5754714012146\n",
      "Epoch 29/200, Loss: 8.028104782104492\n",
      "Epoch 30/200, Loss: 4.227635383605957\n",
      "Epoch 31/200, Loss: 5.717060565948486\n",
      "Epoch 32/200, Loss: 2.386009693145752\n",
      "Epoch 33/200, Loss: 1.6814781427383423\n",
      "Epoch 34/200, Loss: 4.937406063079834\n",
      "Epoch 35/200, Loss: 2.6405158042907715\n",
      "Epoch 36/200, Loss: 1.7314691543579102\n",
      "Epoch 37/200, Loss: 1.8838984966278076\n",
      "Epoch 38/200, Loss: 4.127922058105469\n",
      "Epoch 39/200, Loss: 8.847166061401367\n",
      "Epoch 40/200, Loss: 5.937993049621582\n",
      "Epoch 41/200, Loss: 3.278653621673584\n",
      "Epoch 42/200, Loss: 3.105334997177124\n",
      "Epoch 43/200, Loss: 1.1653087139129639\n",
      "Epoch 44/200, Loss: 1.6624914407730103\n",
      "Epoch 45/200, Loss: 6.719225883483887\n",
      "Epoch 46/200, Loss: 8.356636047363281\n",
      "Epoch 47/200, Loss: 3.432185411453247\n",
      "Epoch 48/200, Loss: 3.5030128955841064\n",
      "Epoch 49/200, Loss: 1.9806369543075562\n",
      "Epoch 50/200, Loss: 5.529433727264404\n",
      "Epoch 51/200, Loss: 2.6759002208709717\n",
      "Epoch 52/200, Loss: 1.0924222469329834\n",
      "Epoch 53/200, Loss: 3.4204983711242676\n",
      "Epoch 54/200, Loss: 3.186939001083374\n",
      "Epoch 55/200, Loss: 2.8705127239227295\n",
      "Epoch 56/200, Loss: 4.878833293914795\n",
      "Epoch 57/200, Loss: 5.69455623626709\n",
      "Epoch 58/200, Loss: 5.612224578857422\n",
      "Epoch 59/200, Loss: 2.623418092727661\n",
      "Epoch 60/200, Loss: 4.9483819007873535\n",
      "Epoch 61/200, Loss: 3.302760362625122\n",
      "Epoch 62/200, Loss: 7.221224784851074\n",
      "Epoch 63/200, Loss: 8.733407974243164\n",
      "Epoch 64/200, Loss: 2.3257391452789307\n",
      "Epoch 65/200, Loss: 5.139950752258301\n",
      "Epoch 66/200, Loss: 5.544450759887695\n",
      "Epoch 67/200, Loss: 4.700058937072754\n",
      "Epoch 68/200, Loss: 0.7357183694839478\n",
      "Epoch 69/200, Loss: 5.076775074005127\n",
      "Epoch 70/200, Loss: 4.3776960372924805\n",
      "Epoch 71/200, Loss: 5.919288635253906\n",
      "Epoch 72/200, Loss: 5.83939266204834\n",
      "Epoch 73/200, Loss: 4.324358940124512\n",
      "Epoch 74/200, Loss: 2.8317902088165283\n",
      "Epoch 75/200, Loss: 3.6544952392578125\n",
      "Epoch 76/200, Loss: 9.471275329589844\n",
      "Epoch 77/200, Loss: 5.264632225036621\n",
      "Epoch 78/200, Loss: 2.3835036754608154\n",
      "Epoch 79/200, Loss: 6.909409999847412\n",
      "Epoch 80/200, Loss: 3.3797860145568848\n",
      "Epoch 81/200, Loss: 2.494980812072754\n",
      "Epoch 82/200, Loss: 0.9102908968925476\n",
      "Epoch 83/200, Loss: 8.971237182617188\n",
      "Epoch 84/200, Loss: 7.525421142578125\n",
      "Epoch 85/200, Loss: 1.9883695840835571\n",
      "Epoch 86/200, Loss: 2.909520387649536\n",
      "Epoch 87/200, Loss: 8.946268081665039\n",
      "Epoch 88/200, Loss: 1.028731346130371\n",
      "Epoch 89/200, Loss: 2.6524319648742676\n",
      "Epoch 90/200, Loss: 5.925212860107422\n",
      "Epoch 91/200, Loss: 5.265119552612305\n",
      "Epoch 92/200, Loss: 1.4593608379364014\n",
      "Epoch 93/200, Loss: 3.4084038734436035\n",
      "Epoch 94/200, Loss: 4.59255313873291\n",
      "Epoch 95/200, Loss: 1.8684011697769165\n",
      "Epoch 96/200, Loss: 8.25114631652832\n",
      "Epoch 97/200, Loss: 2.6681132316589355\n",
      "Epoch 98/200, Loss: 5.0370073318481445\n",
      "Epoch 99/200, Loss: 2.7469823360443115\n",
      "Epoch 100/200, Loss: 5.054787635803223\n",
      "Epoch 101/200, Loss: 3.647728681564331\n",
      "Epoch 102/200, Loss: 7.0769147872924805\n",
      "Epoch 103/200, Loss: 2.1607470512390137\n",
      "Epoch 104/200, Loss: 3.536707639694214\n",
      "Epoch 105/200, Loss: 5.557372093200684\n",
      "Epoch 106/200, Loss: 6.48779296875\n",
      "Epoch 107/200, Loss: 6.294366836547852\n",
      "Epoch 108/200, Loss: 3.217155933380127\n",
      "Epoch 109/200, Loss: 7.252366065979004\n",
      "Epoch 110/200, Loss: 2.9893784523010254\n",
      "Epoch 111/200, Loss: 5.510093688964844\n",
      "Epoch 112/200, Loss: 1.662292718887329\n",
      "Epoch 113/200, Loss: 3.179685592651367\n",
      "Epoch 114/200, Loss: 7.102990627288818\n",
      "Epoch 115/200, Loss: 5.365569114685059\n",
      "Epoch 116/200, Loss: 1.694938063621521\n",
      "Epoch 117/200, Loss: 3.2098629474639893\n",
      "Epoch 118/200, Loss: 1.5975759029388428\n",
      "Epoch 119/200, Loss: 4.762971878051758\n",
      "Epoch 120/200, Loss: 4.2274699211120605\n",
      "Epoch 121/200, Loss: 4.564518928527832\n",
      "Epoch 122/200, Loss: 3.876452922821045\n",
      "Epoch 123/200, Loss: 4.701316833496094\n",
      "Epoch 124/200, Loss: 5.524037837982178\n",
      "Epoch 125/200, Loss: 2.692626476287842\n",
      "Epoch 126/200, Loss: 4.8030314445495605\n",
      "Epoch 127/200, Loss: 5.0360846519470215\n",
      "Epoch 128/200, Loss: 6.288972854614258\n",
      "Epoch 129/200, Loss: 4.900808811187744\n",
      "Epoch 130/200, Loss: 7.48806095123291\n",
      "Epoch 131/200, Loss: 2.552555799484253\n",
      "Epoch 132/200, Loss: 6.1886305809021\n",
      "Epoch 133/200, Loss: 4.1968092918396\n",
      "Epoch 134/200, Loss: 3.0442304611206055\n",
      "Epoch 135/200, Loss: 3.8508732318878174\n",
      "Epoch 136/200, Loss: 4.156798362731934\n",
      "Epoch 137/200, Loss: 5.6817121505737305\n",
      "Epoch 138/200, Loss: 1.6378810405731201\n",
      "Epoch 139/200, Loss: 3.9254531860351562\n",
      "Epoch 140/200, Loss: 7.130224704742432\n",
      "Epoch 141/200, Loss: 4.975578308105469\n",
      "Epoch 142/200, Loss: 1.872123122215271\n",
      "Epoch 143/200, Loss: 3.846186399459839\n",
      "Epoch 144/200, Loss: 2.9416120052337646\n",
      "Epoch 145/200, Loss: 2.992905855178833\n",
      "Epoch 146/200, Loss: 3.6102352142333984\n",
      "Epoch 147/200, Loss: 6.883510589599609\n",
      "Epoch 148/200, Loss: 5.821946620941162\n",
      "Epoch 149/200, Loss: 2.646812915802002\n",
      "Epoch 150/200, Loss: 4.033586502075195\n",
      "Epoch 151/200, Loss: 7.620816707611084\n",
      "Epoch 152/200, Loss: 2.1764960289001465\n",
      "Epoch 153/200, Loss: 3.2905972003936768\n",
      "Epoch 154/200, Loss: 1.7559337615966797\n",
      "Epoch 155/200, Loss: 3.789109706878662\n",
      "Epoch 156/200, Loss: 5.203679084777832\n",
      "Epoch 157/200, Loss: 3.211223602294922\n",
      "Epoch 158/200, Loss: 0.7716027498245239\n",
      "Epoch 159/200, Loss: 5.69402551651001\n",
      "Epoch 160/200, Loss: 4.791104316711426\n",
      "Epoch 161/200, Loss: 5.895572662353516\n",
      "Epoch 162/200, Loss: 3.1569671630859375\n",
      "Epoch 163/200, Loss: 4.16860818862915\n",
      "Epoch 164/200, Loss: 5.4607648849487305\n",
      "Epoch 165/200, Loss: 6.378964900970459\n",
      "Epoch 166/200, Loss: 3.6225650310516357\n",
      "Epoch 167/200, Loss: 7.721841335296631\n",
      "Epoch 168/200, Loss: 10.695249557495117\n",
      "Epoch 169/200, Loss: 5.966134071350098\n",
      "Epoch 170/200, Loss: 3.4834532737731934\n",
      "Epoch 171/200, Loss: 7.687600135803223\n",
      "Epoch 172/200, Loss: 3.8495335578918457\n",
      "Epoch 173/200, Loss: 6.494421482086182\n",
      "Epoch 174/200, Loss: 5.860196590423584\n",
      "Epoch 175/200, Loss: 7.175352573394775\n",
      "Epoch 176/200, Loss: 4.066513538360596\n",
      "Epoch 177/200, Loss: 2.283386707305908\n",
      "Epoch 178/200, Loss: 0.9756875038146973\n",
      "Epoch 179/200, Loss: 4.12058162689209\n",
      "Epoch 180/200, Loss: 6.834730625152588\n",
      "Epoch 181/200, Loss: 4.220883369445801\n",
      "Epoch 182/200, Loss: 9.435104370117188\n",
      "Epoch 183/200, Loss: 3.241126537322998\n",
      "Epoch 184/200, Loss: 4.78848934173584\n",
      "Epoch 185/200, Loss: 7.711884498596191\n",
      "Epoch 186/200, Loss: 7.203784942626953\n",
      "Epoch 187/200, Loss: 5.053044319152832\n",
      "Epoch 188/200, Loss: 7.456973075866699\n",
      "Epoch 189/200, Loss: 3.3263347148895264\n",
      "Epoch 190/200, Loss: 4.585558891296387\n",
      "Epoch 191/200, Loss: 6.319581031799316\n",
      "Epoch 192/200, Loss: 4.571703910827637\n",
      "Epoch 193/200, Loss: 2.8125452995300293\n",
      "Epoch 194/200, Loss: 8.11845874786377\n",
      "Epoch 195/200, Loss: 5.900483131408691\n",
      "Epoch 196/200, Loss: 0.9831738471984863\n",
      "Epoch 197/200, Loss: 6.470057010650635\n",
      "Epoch 198/200, Loss: 5.693286418914795\n",
      "Epoch 199/200, Loss: 5.9322333335876465\n",
      "Epoch 200/200, Loss: 2.1055054664611816\n",
      "MSE: 2.272573563787672\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-3', clean_root_dir='Sequences/clean', model_path='alter3_non_binary_model_reg.pth',is_binary=False, is_regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140, Test size: 36\n",
      "Train size: 140, Test size: 36\n",
      "Epoch 1/200, Loss: 3.294516086578369\n",
      "Epoch 2/200, Loss: 2.7851314544677734\n",
      "Epoch 3/200, Loss: 10.486544609069824\n",
      "Epoch 4/200, Loss: 7.340144157409668\n",
      "Epoch 5/200, Loss: 2.2285287380218506\n",
      "Epoch 6/200, Loss: 10.41717529296875\n",
      "Epoch 7/200, Loss: 2.161707639694214\n",
      "Epoch 8/200, Loss: 2.539578914642334\n",
      "Epoch 9/200, Loss: 2.8201940059661865\n",
      "Epoch 10/200, Loss: 3.7105636596679688\n",
      "Epoch 11/200, Loss: 2.5429606437683105\n",
      "Epoch 12/200, Loss: 10.678439140319824\n",
      "Epoch 13/200, Loss: 3.8955509662628174\n",
      "Epoch 14/200, Loss: 3.8432705402374268\n",
      "Epoch 15/200, Loss: 2.9325766563415527\n",
      "Epoch 16/200, Loss: 0.9890642166137695\n",
      "Epoch 17/200, Loss: 6.339295387268066\n",
      "Epoch 18/200, Loss: 2.635526418685913\n",
      "Epoch 19/200, Loss: 5.123396396636963\n",
      "Epoch 20/200, Loss: 7.919320106506348\n",
      "Epoch 21/200, Loss: 2.552957534790039\n",
      "Epoch 22/200, Loss: 14.8341646194458\n",
      "Epoch 23/200, Loss: 4.694510459899902\n",
      "Epoch 24/200, Loss: 1.630761742591858\n",
      "Epoch 25/200, Loss: 5.3443403244018555\n",
      "Epoch 26/200, Loss: 4.038193225860596\n",
      "Epoch 27/200, Loss: 3.462446689605713\n",
      "Epoch 28/200, Loss: 0.27595072984695435\n",
      "Epoch 29/200, Loss: 2.3882803916931152\n",
      "Epoch 30/200, Loss: 2.675565004348755\n",
      "Epoch 31/200, Loss: 3.639697551727295\n",
      "Epoch 32/200, Loss: 1.704932451248169\n",
      "Epoch 33/200, Loss: 4.646328926086426\n",
      "Epoch 34/200, Loss: 5.9123358726501465\n",
      "Epoch 35/200, Loss: 6.929865837097168\n",
      "Epoch 36/200, Loss: 3.2934889793395996\n",
      "Epoch 37/200, Loss: 1.3560149669647217\n",
      "Epoch 38/200, Loss: 1.3506522178649902\n",
      "Epoch 39/200, Loss: 1.9140514135360718\n",
      "Epoch 40/200, Loss: 6.059185981750488\n",
      "Epoch 41/200, Loss: 2.423823595046997\n",
      "Epoch 42/200, Loss: 2.998720645904541\n",
      "Epoch 43/200, Loss: 1.6454315185546875\n",
      "Epoch 44/200, Loss: 2.7200844287872314\n",
      "Epoch 45/200, Loss: 0.8697552680969238\n",
      "Epoch 46/200, Loss: 4.232046604156494\n",
      "Epoch 47/200, Loss: 3.260554075241089\n",
      "Epoch 48/200, Loss: 2.922499179840088\n",
      "Epoch 49/200, Loss: 5.995208263397217\n",
      "Epoch 50/200, Loss: 4.949305057525635\n",
      "Epoch 51/200, Loss: 3.8727526664733887\n",
      "Epoch 52/200, Loss: 5.041611194610596\n",
      "Epoch 53/200, Loss: 6.5438127517700195\n",
      "Epoch 54/200, Loss: 3.698314666748047\n",
      "Epoch 55/200, Loss: 4.556727886199951\n",
      "Epoch 56/200, Loss: 3.226868152618408\n",
      "Epoch 57/200, Loss: 10.378277778625488\n",
      "Epoch 58/200, Loss: 5.303366661071777\n",
      "Epoch 59/200, Loss: 2.903459072113037\n",
      "Epoch 60/200, Loss: 7.387944221496582\n",
      "Epoch 61/200, Loss: 1.7923179864883423\n",
      "Epoch 62/200, Loss: 6.145143985748291\n",
      "Epoch 63/200, Loss: 4.219788074493408\n",
      "Epoch 64/200, Loss: 3.3906707763671875\n",
      "Epoch 65/200, Loss: 1.9924933910369873\n",
      "Epoch 66/200, Loss: 3.415433883666992\n",
      "Epoch 67/200, Loss: 0.8498014211654663\n",
      "Epoch 68/200, Loss: 3.1822681427001953\n",
      "Epoch 69/200, Loss: 2.1009085178375244\n",
      "Epoch 70/200, Loss: 4.030238151550293\n",
      "Epoch 71/200, Loss: 1.4684407711029053\n",
      "Epoch 72/200, Loss: 1.6767162084579468\n",
      "Epoch 73/200, Loss: 2.1894936561584473\n",
      "Epoch 74/200, Loss: 2.056885242462158\n",
      "Epoch 75/200, Loss: 4.53430700302124\n",
      "Epoch 76/200, Loss: 1.32929265499115\n",
      "Epoch 77/200, Loss: 1.5958611965179443\n",
      "Epoch 78/200, Loss: 4.079849720001221\n",
      "Epoch 79/200, Loss: 3.7066397666931152\n",
      "Epoch 80/200, Loss: 4.2868499755859375\n",
      "Epoch 81/200, Loss: 3.230133056640625\n",
      "Epoch 82/200, Loss: 6.123610973358154\n",
      "Epoch 83/200, Loss: 3.502044200897217\n",
      "Epoch 84/200, Loss: 7.697046756744385\n",
      "Epoch 85/200, Loss: 8.43497371673584\n",
      "Epoch 86/200, Loss: 2.0542728900909424\n",
      "Epoch 87/200, Loss: 4.455435276031494\n",
      "Epoch 88/200, Loss: 0.8978368043899536\n",
      "Epoch 89/200, Loss: 1.7803865671157837\n",
      "Epoch 90/200, Loss: 4.3607378005981445\n",
      "Epoch 91/200, Loss: 6.313902378082275\n",
      "Epoch 92/200, Loss: 3.3780159950256348\n",
      "Epoch 93/200, Loss: 4.149012565612793\n",
      "Epoch 94/200, Loss: 4.855490207672119\n",
      "Epoch 95/200, Loss: 2.0016114711761475\n",
      "Epoch 96/200, Loss: 3.184441566467285\n",
      "Epoch 97/200, Loss: 4.013360977172852\n",
      "Epoch 98/200, Loss: 1.2844752073287964\n",
      "Epoch 99/200, Loss: 3.8260931968688965\n",
      "Epoch 100/200, Loss: 6.514519691467285\n",
      "Epoch 101/200, Loss: 5.558504104614258\n",
      "Epoch 102/200, Loss: 2.117736339569092\n",
      "Epoch 103/200, Loss: 4.014967918395996\n",
      "Epoch 104/200, Loss: 1.4019423723220825\n",
      "Epoch 105/200, Loss: 6.7916998863220215\n",
      "Epoch 106/200, Loss: 3.214359760284424\n",
      "Epoch 107/200, Loss: 2.5560078620910645\n",
      "Epoch 108/200, Loss: 4.503670692443848\n",
      "Epoch 109/200, Loss: 4.241440296173096\n",
      "Epoch 110/200, Loss: 0.8221352696418762\n",
      "Epoch 111/200, Loss: 1.2036659717559814\n",
      "Epoch 112/200, Loss: 0.032008569687604904\n",
      "Epoch 113/200, Loss: 1.678527593612671\n",
      "Epoch 114/200, Loss: 6.386536121368408\n",
      "Epoch 115/200, Loss: 2.7258360385894775\n",
      "Epoch 116/200, Loss: 1.7204910516738892\n",
      "Epoch 117/200, Loss: 3.939225673675537\n",
      "Epoch 118/200, Loss: 4.912054538726807\n",
      "Epoch 119/200, Loss: 4.934784889221191\n",
      "Epoch 120/200, Loss: 1.522110939025879\n",
      "Epoch 121/200, Loss: 7.051445007324219\n",
      "Epoch 122/200, Loss: 3.011038303375244\n",
      "Epoch 123/200, Loss: 6.6439361572265625\n",
      "Epoch 124/200, Loss: 6.415687561035156\n",
      "Epoch 125/200, Loss: 1.9255071878433228\n",
      "Epoch 126/200, Loss: 6.610243320465088\n",
      "Epoch 127/200, Loss: 1.852461814880371\n",
      "Epoch 128/200, Loss: 5.3136749267578125\n",
      "Epoch 129/200, Loss: 5.836459636688232\n",
      "Epoch 130/200, Loss: 10.582119941711426\n",
      "Epoch 131/200, Loss: 4.8493547439575195\n",
      "Epoch 132/200, Loss: 3.2246315479278564\n",
      "Epoch 133/200, Loss: 3.7514164447784424\n",
      "Epoch 134/200, Loss: 3.8121838569641113\n",
      "Epoch 135/200, Loss: 5.047880172729492\n",
      "Epoch 136/200, Loss: 4.035748481750488\n",
      "Epoch 137/200, Loss: 4.396353244781494\n",
      "Epoch 138/200, Loss: 7.729109287261963\n",
      "Epoch 139/200, Loss: 2.784060001373291\n",
      "Epoch 140/200, Loss: 7.803933620452881\n",
      "Epoch 141/200, Loss: 1.4473159313201904\n",
      "Epoch 142/200, Loss: 6.879405975341797\n",
      "Epoch 143/200, Loss: 6.182291030883789\n",
      "Epoch 144/200, Loss: 3.8209621906280518\n",
      "Epoch 145/200, Loss: 3.478576183319092\n",
      "Epoch 146/200, Loss: 1.9274898767471313\n",
      "Epoch 147/200, Loss: 2.3263721466064453\n",
      "Epoch 148/200, Loss: 4.48372745513916\n",
      "Epoch 149/200, Loss: 4.379261016845703\n",
      "Epoch 150/200, Loss: 2.7342193126678467\n",
      "Epoch 151/200, Loss: 4.291491508483887\n",
      "Epoch 152/200, Loss: 1.618735909461975\n",
      "Epoch 153/200, Loss: 1.061208963394165\n",
      "Epoch 154/200, Loss: 2.039470911026001\n",
      "Epoch 155/200, Loss: 4.016798496246338\n",
      "Epoch 156/200, Loss: 3.270540237426758\n",
      "Epoch 157/200, Loss: 2.066408395767212\n",
      "Epoch 158/200, Loss: 3.7923741340637207\n",
      "Epoch 159/200, Loss: 1.9319738149642944\n",
      "Epoch 160/200, Loss: 3.9391732215881348\n",
      "Epoch 161/200, Loss: 6.071854591369629\n",
      "Epoch 162/200, Loss: 3.1430468559265137\n",
      "Epoch 163/200, Loss: 7.040622711181641\n",
      "Epoch 164/200, Loss: 3.286492109298706\n",
      "Epoch 165/200, Loss: 3.133270740509033\n",
      "Epoch 166/200, Loss: 3.1587257385253906\n",
      "Epoch 167/200, Loss: 6.480810642242432\n",
      "Epoch 168/200, Loss: 3.2848522663116455\n",
      "Epoch 169/200, Loss: 6.4337005615234375\n",
      "Epoch 170/200, Loss: 2.906317949295044\n",
      "Epoch 171/200, Loss: 2.0662453174591064\n",
      "Epoch 172/200, Loss: 2.893157482147217\n",
      "Epoch 173/200, Loss: 3.624908924102783\n",
      "Epoch 174/200, Loss: 3.462648868560791\n",
      "Epoch 175/200, Loss: 5.798707485198975\n",
      "Epoch 176/200, Loss: 4.543125152587891\n",
      "Epoch 177/200, Loss: 0.8487617373466492\n",
      "Epoch 178/200, Loss: 3.8020758628845215\n",
      "Epoch 179/200, Loss: 3.4244136810302734\n",
      "Epoch 180/200, Loss: 7.217408180236816\n",
      "Epoch 181/200, Loss: 2.9710512161254883\n",
      "Epoch 182/200, Loss: 0.5255836844444275\n",
      "Epoch 183/200, Loss: 2.184892416000366\n",
      "Epoch 184/200, Loss: 5.914435386657715\n",
      "Epoch 185/200, Loss: 5.687003135681152\n",
      "Epoch 186/200, Loss: 2.8870701789855957\n",
      "Epoch 187/200, Loss: 0.9995309710502625\n",
      "Epoch 188/200, Loss: 4.867313385009766\n",
      "Epoch 189/200, Loss: 3.3590569496154785\n",
      "Epoch 190/200, Loss: 5.182457447052002\n",
      "Epoch 191/200, Loss: 4.077855587005615\n",
      "Epoch 192/200, Loss: 3.2192726135253906\n",
      "Epoch 193/200, Loss: 1.8875916004180908\n",
      "Epoch 194/200, Loss: 3.30228853225708\n",
      "Epoch 195/200, Loss: 1.3755297660827637\n",
      "Epoch 196/200, Loss: 4.0281877517700195\n",
      "Epoch 197/200, Loss: 4.5380988121032715\n",
      "Epoch 198/200, Loss: 1.0396645069122314\n",
      "Epoch 199/200, Loss: 3.685887575149536\n",
      "Epoch 200/200, Loss: 7.402623176574707\n",
      "MSE: 2.5451699693997702\n"
     ]
    }
   ],
   "source": [
    "PoisonDetector.run(adv_root_dir='Sequences/alter-5/', clean_root_dir='Sequences/clean/', model_path='alter5_non_binary_model.pth',is_binary=False, is_regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
